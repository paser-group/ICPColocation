{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm, tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_file (filename):\n",
    "    df = pd.read_csv(filename)  # read the csv file\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_to_numeric(label):\n",
    "    converted_label = np.empty(len(label), dtype=object) \n",
    "    for i in range(len(label)):\n",
    "        if label[i] == \"ONLY_ONE\":\n",
    "            converted_label[i] = 1\n",
    "        elif label[i] == \"NEUTRAL\":\n",
    "            converted_label[i] = 0\n",
    "        else: \n",
    "            converted_label[i] = 2\n",
    "    converted_label = converted_label.astype('int')\n",
    "    return converted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_PCA(train, test):\n",
    "    # Since PCA is effected by scale, we need to scale the features in the data before applying PCA\n",
    "    scaler = StandardScaler()\n",
    "    # Fit on training set only.\n",
    "    scaler.fit(train)\n",
    "    # Apply transform to both the training set and the test set.\n",
    "    train = scaler.transform(train)\n",
    "    test = scaler.transform(test)\n",
    "\n",
    "    # Make an instance of the Model\n",
    "    pca = PCA(.95) #  choose the minimum number of principal components such that 95% of the variance is retained.\n",
    "    # We are fitting PCA on the training set only.\n",
    "    pca.fit(train)\n",
    "    #print (\"Number of selected components: \", pca.n_components_)\n",
    "    #print (pd.DataFrame(pca.components_))\n",
    "    \n",
    "    # Apply the mapping (transform) to both the training set and the test set\n",
    "    #print(\"Before applying PCA train set size: \", train.shape)\n",
    "    #print(\"Before applying PCA test set size: \", test.shape)\n",
    "    train = pca.transform(train)\n",
    "    test = pca.transform(test)\n",
    "    #print(\"After applying PCA train set size: \", train.shape)\n",
    "    #print(\"After applying PCA test set size: \", test.shape)\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_CART(train, test, train_label, test_label):\n",
    "    clf = tree.DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                                      min_samples_split = 2, min_weight_fraction_leaf=0.0)\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_KNN(train, test, train_label, test_label):\n",
    "    clf = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_SVM(train, test, train_label, test_label):\n",
    "    clf = svm.SVC(gamma='auto', C = 20.0, kernel='rbf', class_weight = {0:1, 1:1, 2:5})\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_NB(train, test, train_label, test_label):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_RF(train, test, train_label, test_label):\n",
    "    clf = RandomForestClassifier(n_estimators=10, criterion='gini')\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance(true_label, predicted_label):   \n",
    "    precision = recall = f1 = np.zeros(3, dtype=np.float32)\n",
    "    report = classification_report(true_label, predicted_label)\n",
    "    precision = precision_score(true_label, predicted_label, average=None, labels=[0,1,2])\n",
    "    recall = recall_score(true_label, predicted_label, average=None, labels=[0,1,2])\n",
    "    f1 = f1_score(true_label, predicted_label, average=None, labels=[0,1,2])\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cv(data, true_label):\n",
    "    # 10 fold cv\n",
    "    kf = KFold(n_splits=10, shuffle = True, random_state = 7)\n",
    "\n",
    "    cv_recall_DT = []\n",
    "    cv_precision_DT = []\n",
    "    cv_f1_DT = []\n",
    "\n",
    "    cv_recall_KNN = []\n",
    "    cv_precision_KNN = []\n",
    "    cv_f1_KNN = []\n",
    "\n",
    "    cv_recall_SVM = []\n",
    "    cv_precision_SVM = []\n",
    "    cv_f1_SVM = []\n",
    "\n",
    "    cv_recall_NB = []\n",
    "    cv_precision_NB = []\n",
    "    cv_f1_NB = []\n",
    "\n",
    "    cv_recall_RF = []\n",
    "    cv_precision_RF = []\n",
    "    cv_f1_RF = []\n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train, test = data.loc[train_index], data.loc[test_index]\n",
    "        train_label, test_label = true_label[train_index], true_label[test_index]\n",
    "\n",
    "        train, test = apply_PCA(train, test)\n",
    "\n",
    "        recall, precision, f1 = perfrom_CART(train, test, train_label, test_label)\n",
    "        cv_recall_DT.append(recall)\n",
    "        cv_precision_DT.append(precision)\n",
    "        cv_f1_DT.append(f1)\n",
    "\n",
    "        recall, precision, f1 = perfrom_KNN(train, test, train_label, test_label)\n",
    "        cv_recall_KNN.append(recall)\n",
    "        cv_precision_KNN.append(precision)\n",
    "        cv_f1_KNN.append(f1)\n",
    "\n",
    "        recall, precision, f1 = perfrom_SVM(train, test, train_label, test_label)\n",
    "        cv_recall_SVM.append(recall)\n",
    "        cv_precision_SVM.append(precision)\n",
    "        cv_f1_SVM.append(f1)\n",
    "\n",
    "        recall, precision, f1 = perfrom_NB(train, test, train_label, test_label)\n",
    "        cv_recall_NB.append(recall)\n",
    "        cv_precision_NB.append(precision)\n",
    "        cv_f1_NB.append(f1)\n",
    "\n",
    "        recall, precision, f1 = perfrom_RF(train, test, train_label, test_label)\n",
    "        cv_recall_RF.append(recall)\n",
    "        cv_precision_RF.append(precision)\n",
    "        cv_f1_RF.append(f1)\n",
    "\n",
    "        \n",
    "    recall_DT = np.mean(cv_recall_DT, axis= 0)\n",
    "    precision_DT = np.mean(cv_precision_DT, axis= 0)\n",
    "    f1_DT = np.mean(cv_f1_DT, axis= 0)\n",
    "\n",
    "    recall_KNN = np.mean(cv_recall_KNN, axis= 0)\n",
    "    precision_KNN = np.mean(cv_precision_KNN, axis= 0)\n",
    "    f1_KNN = np.mean(cv_f1_KNN, axis= 0)\n",
    "\n",
    "    recall_SVM = np.mean(cv_recall_SVM, axis= 0)\n",
    "    precision_SVM = np.mean(cv_precision_SVM, axis= 0)\n",
    "    f1_SVM =  np.mean(cv_f1_SVM, axis= 0)\n",
    "\n",
    "    recall_NB = np.mean(cv_recall_NB, axis= 0)\n",
    "    precision_NB = np.mean(cv_precision_NB, axis= 0)\n",
    "    f1_NB = np.mean(cv_f1_NB, axis= 0)\n",
    "\n",
    "    recall_RF = np.mean(cv_recall_RF, axis= 0)\n",
    "    precision_RF = np.mean(cv_precision_RF, axis= 0)\n",
    "    f1_RF = np.mean(cv_f1_RF, axis= 0)\n",
    "    \n",
    "    return recall_DT, precision_DT, f1_DT, recall_KNN, precision_KNN, f1_KNN, recall_SVM, precision_SVM,\\\n",
    "    f1_SVM, recall_NB, precision_NB, f1_NB, recall_RF, precision_RF, f1_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def different_file_test(train, test, train_label, test_label):\n",
    "    \n",
    "    train, test = apply_PCA(train, test)\n",
    "        \n",
    "    recall_DT, precision_DT, f1_DT = perfrom_CART(train, test, train_label, test_label)\n",
    "    recall_KNN, precision_KNN, f1_KNN = perfrom_KNN(train, test, train_label, test_label)\n",
    "    recall_SVM, precision_SVM, f1_SVM = perfrom_SVM(train, test, train_label, test_label)\n",
    "    recall_NB, precision_NB, f1_NB = perfrom_NB(train, test, train_label, test_label)\n",
    "    recall_RF, precision_RF, f1_RF = perfrom_RF(train, test, train_label, test_label)\n",
    "\n",
    "    return recall_DT, precision_DT, f1_DT, recall_KNN, precision_KNN, f1_KNN, recall_SVM, precision_SVM,\\\n",
    "    f1_SVM, recall_NB, precision_NB, f1_NB, recall_RF, precision_RF, f1_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_test(data, true_label, train_data, test_data, train_label, test_label, test_name):\n",
    "    repeated_recall_DT = []\n",
    "    repeated_precision_DT = []\n",
    "    repeated_f1_DT = []\n",
    "\n",
    "    repeated_recall_KNN = []\n",
    "    repeated_precision_KNN = []\n",
    "    repeated_f1_KNN = []\n",
    "\n",
    "    repeated_recall_SVM = []\n",
    "    repeated_precision_SVM = []\n",
    "    repeated_f1_SVM = []\n",
    "\n",
    "    repeated_recall_NB = []\n",
    "    repeated_precision_NB = []\n",
    "    repeated_f1_NB = []\n",
    "\n",
    "    repeated_recall_RF = []\n",
    "    repeated_precision_RF = []\n",
    "    repeated_f1_RF = []\n",
    "    \n",
    "    recall_DT= precision_DT= f1_DT= recall_KNN= precision_KNN= f1_KNN= recall_SVM= precision_SVM= f1_SVM\\\n",
    "    = recall_NB= precision_NB= f1_NB= recall_RF= precision_RF= f1_RF = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        if test_name == \"k_fold\":\n",
    "            recall_DT, precision_DT, f1_DT, recall_KNN, precision_KNN, f1_KNN, recall_SVM, precision_SVM, f1_SVM,\\\n",
    "            recall_NB, precision_NB, f1_NB, recall_RF, precision_RF, f1_RF = kfold_cv(data, true_label)\n",
    "        else: \n",
    "            recall_DT, precision_DT, f1_DT, recall_KNN, precision_KNN, f1_KNN, recall_SVM, precision_SVM, f1_SVM,\\\n",
    "            recall_NB, precision_NB, f1_NB, recall_RF, precision_RF, f1_RF = different_file_test(train_data, test_data, train_label, test_label)\n",
    "        \n",
    "        repeated_recall_DT.append(recall_DT)\n",
    "        repeated_precision_DT.append(precision_DT)\n",
    "        repeated_f1_DT.append(f1_DT)\n",
    "\n",
    "        repeated_recall_KNN.append(recall_KNN)\n",
    "        repeated_precision_KNN.append(precision_KNN)\n",
    "        repeated_f1_KNN.append(f1_KNN)\n",
    "\n",
    "        repeated_recall_SVM.append(recall_SVM)\n",
    "        repeated_precision_SVM.append(precision_SVM)\n",
    "        repeated_f1_SVM.append(f1_SVM)\n",
    "\n",
    "        repeated_recall_NB.append(recall_NB)\n",
    "        repeated_precision_NB.append(precision_NB)\n",
    "        repeated_f1_NB.append(f1_NB)\n",
    "\n",
    "        repeated_recall_RF.append(recall_RF)\n",
    "        repeated_precision_RF.append(precision_RF)\n",
    "        repeated_f1_RF.append(f1_RF)\n",
    "        \n",
    "    print(\"-------DT-------\")\n",
    "    print(\"Recall:\", np.median(repeated_recall_DT, axis= 0))\n",
    "    print(\"Precision:\", np.median(repeated_precision_DT, axis= 0))\n",
    "    print(\"f1 score:\", np.median(repeated_f1_DT, axis= 0))\n",
    "\n",
    "    print(\"-------KNN-------\")\n",
    "    print(\"Recall:\", np.median(repeated_recall_KNN, axis= 0))\n",
    "    print(\"Precision:\", np.median(repeated_precision_KNN, axis= 0))\n",
    "    print(\"f1 score:\", np.median(repeated_f1_KNN, axis= 0))\n",
    "\n",
    "    print(\"-------SVM-------\")\n",
    "    print(\"Recall:\", np.median(repeated_recall_SVM, axis= 0))\n",
    "    print(\"Precision:\", np.median(repeated_precision_SVM, axis= 0))\n",
    "    print(\"f1 score:\", np.median(repeated_f1_SVM, axis= 0))\n",
    "\n",
    "    print(\"-------NB-------\")\n",
    "    print(\"Recall:\", np.median(repeated_recall_NB, axis= 0))\n",
    "    print(\"Precision:\", np.median(repeated_precision_NB, axis= 0))\n",
    "    print(\"f1 score:\", np.median(repeated_f1_NB, axis= 0))\n",
    "\n",
    "    print(\"-------RF-------\")\n",
    "    print(\"Recall:\", np.median(repeated_recall_RF, axis= 0))\n",
    "    print(\"Precision:\", np.median(repeated_precision_RF, axis= 0))\n",
    "    print(\"f1 score:\", np.median(repeated_f1_RF, axis= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcFeatureImp(feature_vec, label_vec, feature_names_param, repeat=10):\n",
    "    header_str, output= '', ''\n",
    "    for name_ in feature_names_param:\n",
    "        header_str = header_str + name_ + ','\n",
    "    theRndForestModel = RandomForestClassifier()\n",
    "    theRndForestModel.fit(feature_vec, label_vec)\n",
    "    feat_imp_vector=theRndForestModel.feature_importances_\n",
    "\n",
    "    for ind_ in range(repeat):\n",
    "        for imp_vec_index in range(len(feat_imp_vector)):\n",
    "            feat_imp_val = round(feat_imp_vector[imp_vec_index], 5)\n",
    "            output = output +  str(feat_imp_val) + ','\n",
    "        output = output + '\\n'\n",
    "    output_status = header_str + '\\n' + output\n",
    "    #print (\"Feature importance: \", output_status)\n",
    "    \n",
    "    feat_imp_vector=list(feat_imp_vector)\n",
    "    sorted_feat_imp_vector= [x_ for x_ in feat_imp_vector]\n",
    "    sorted_feat_imp_vector.sort(reverse=True)\n",
    "    \n",
    "    sorted_feature_name = []\n",
    "    for feat_imp_val in sorted_feat_imp_vector:\n",
    "        feat_index = feat_imp_vector.index(feat_imp_val) \n",
    "        sorted_feature_name.append(feature_names_param[feat_index])\n",
    "        \n",
    "    print (\"sorted feature names: \", sorted_feature_name)\n",
    "    print (\"sorted feature importance: \", sorted_feat_imp_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, true_label, train_data, test_data, train_label, test_label = [], [], [], [], [], [] # necessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set: COLOCATED_MOZILLA.csv\n",
      "Initial data shape:  (1613, 16)\n",
      "-------DT-------\n",
      "Recall: [0.96050196 0.86052198 0.85900174]\n",
      "Precision: [0.97475894 0.75953755 0.82572647]\n",
      "f1 score: [0.96745177 0.7855099  0.83691895]\n",
      "-------KNN-------\n",
      "Recall: [0.97714871 0.86699634 0.85482835]\n",
      "Precision: [0.97130508 0.8698138  0.8825487 ]\n",
      "f1 score: [0.9741529  0.86254302 0.86627848]\n",
      "-------SVM-------\n",
      "Recall: [0.93800623 0.36703297 0.7730844 ]\n",
      "Precision: [0.93229627 0.7497619  0.6320801 ]\n",
      "f1 score: [0.93488611 0.48641539 0.68892872]\n",
      "-------NB-------\n",
      "Recall: [0.92018843 0.13440476 0.2707983 ]\n",
      "Precision: [0.85496542 0.24       0.35075538]\n",
      "f1 score: [0.88584689 0.15109082 0.30274131]\n",
      "-------RF-------\n",
      "Recall: [0.98157159 0.72940934 0.77514864]\n",
      "Precision: [0.95261326 0.86052503 0.89526931]\n",
      "f1 score: [0.96664785 0.78057835 0.83821221]\n",
      "sorted feature names:  ['SLOC', 'HARD_CODE', 'ATTR', 'URL', 'INCL', 'COMMENT', 'ENS', 'REQ', 'CMD', 'FILE', 'FILE_MODE', 'SSH']\n",
      "sorted feature importance:  [0.21977242079810236, 0.1710128538761334, 0.13906565382543226, 0.10672633253637447, 0.0700008161630261, 0.06331957569427828, 0.06088776740858538, 0.04953641823117159, 0.04392662041735403, 0.04180643734531883, 0.0339451037042233, 0.0]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_MOZILLA.csv') \n",
    "print(\"Data set: COLOCATED_MOZILLA.csv\")\n",
    "print(\"Initial data shape: \", data.shape)\n",
    "true_label = data['COLOCATED_STATUS']\n",
    "true_label = convert_label_to_numeric(true_label)\n",
    "data = data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "repeated_test(data, true_label, train_data, test_data, train_label, test_label, \"k_fold\") #repeat kfold 10 times and report avarage performance\n",
    "\n",
    "columns_name = list(data.columns.values) # read all column names\n",
    "calcFeatureImp(data, true_label, columns_name) # find feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set: COLOCATED_OPENSTACK.csv\n",
      "Initial data shape:  (2764, 16)\n",
      "-------DT-------\n",
      "Recall: [0.83419317 0.17592692 0.65614025]\n",
      "Precision: [0.84772966 0.17021454 0.64007608]\n",
      "f1 score: [0.84025935 0.16630119 0.64742559]\n",
      "-------KNN-------\n",
      "Recall: [0.8947942  0.05582796 0.68889839]\n",
      "Precision: [0.84439477 0.19277778 0.71628359]\n",
      "f1 score: [0.86863789 0.08256557 0.70063758]\n",
      "-------SVM-------\n",
      "Recall: [0.7086892  0.02789433 0.84278456]\n",
      "Precision: [0.89674136 0.06666667 0.51792268]\n",
      "f1 score: [0.79135969 0.03759804 0.64118245]\n",
      "-------NB-------\n",
      "Recall: [0.93956549 0.06507039 0.32406956]\n",
      "Precision: [0.74122986 0.26428571 0.67129139]\n",
      "f1 score: [0.82843356 0.09645667 0.43564587]\n",
      "-------RF-------\n",
      "Recall: [0.90093732 0.07974839 0.66135016]\n",
      "Precision: [0.83523306 0.24684524 0.71197049]\n",
      "f1 score: [0.86711376 0.11662414 0.6838848 ]\n",
      "sorted feature names:  ['HARD_CODE', 'SLOC', 'ATTR', 'COMMENT', 'URL', 'ENS', 'INCL', 'REQ', 'CMD', 'FILE', 'FILE_MODE', 'SSH']\n",
      "sorted feature importance:  [0.22273903204074955, 0.16959164680344088, 0.15676902847140467, 0.12312752156628441, 0.10784117920923063, 0.055958343674922216, 0.049784691484795036, 0.03977346441880902, 0.030458378532479125, 0.025018447252585584, 0.018799796290143115, 0.0001384702551557646]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_OPENSTACK.csv') \n",
    "print(\"Data set: COLOCATED_OPENSTACK.csv\")\n",
    "print(\"Initial data shape: \", data.shape)\n",
    "true_label = data['COLOCATED_STATUS']\n",
    "true_label = convert_label_to_numeric(true_label)\n",
    "data = data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "repeated_test(data, true_label, train_data, test_data, train_label, test_label, \"k_fold\") #repeat kfold 10 times and report avarage performance\n",
    "\n",
    "columns_name = list(data.columns.values) # read all column names\n",
    "calcFeatureImp(data, true_label, columns_name) # find feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set: COLOCATED_WIKIMEDIA.csv\n",
      "Initial data shape:  (2845, 16)\n",
      "-------DT-------\n",
      "Recall: [0.8170178  0.17228026 0.4349699 ]\n",
      "Precision: [0.81751151 0.15290754 0.45022698]\n",
      "f1 score: [0.81678518 0.15797012 0.43998046]\n",
      "-------KNN-------\n",
      "Recall: [0.89905329 0.11156079 0.43120454]\n",
      "Precision: [0.80591502 0.28174603 0.54830925]\n",
      "f1 score: [0.84968552 0.15563023 0.47977294]\n",
      "-------SVM-------\n",
      "Recall: [0.72317665 0.01130952 0.65357168]\n",
      "Precision: [0.83499016 0.045      0.35194502]\n",
      "f1 score: [0.77474481 0.01766917 0.45556341]\n",
      "-------NB-------\n",
      "Recall: [0.93734606 0.01309524 0.25734362]\n",
      "Precision: [0.77028988 0.05333333 0.50922704]\n",
      "f1 score: [0.84555845 0.02102564 0.34032561]\n",
      "-------RF-------\n",
      "Recall: [0.9156549  0.07574769 0.38036871]\n",
      "Precision: [0.79745821 0.31404762 0.53160471]\n",
      "f1 score: [0.8511604  0.114326   0.43907036]\n",
      "sorted feature names:  ['SLOC', 'ATTR', 'HARD_CODE', 'COMMENT', 'ENS', 'INCL', 'CMD', 'REQ', 'URL', 'FILE', 'FILE_MODE', 'SSH']\n",
      "sorted feature importance:  [0.2102332740039162, 0.15817645780564882, 0.1567748317377349, 0.12989894181224532, 0.05954286574971618, 0.054865253040418616, 0.051203213211724156, 0.04967011199443234, 0.04496052837480864, 0.042630055789968146, 0.041977933315668334, 6.653316371833539e-05]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_WIKIMEDIA.csv') \n",
    "print(\"Data set: COLOCATED_WIKIMEDIA.csv\")\n",
    "print(\"Initial data shape: \", data.shape)\n",
    "true_label = data['COLOCATED_STATUS']\n",
    "true_label = convert_label_to_numeric(true_label)\n",
    "data = data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "repeated_test(data, true_label, train_data, test_data, train_label, test_label, \"k_fold\") # repeat kfold 10 times and report avarage performance\n",
    "\n",
    "columns_name = list(data.columns.values) # read all column names\n",
    "calcFeatureImp(data, true_label, columns_name) # find feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: COLOCATED_MOZILLA.csv\n",
      "Initial data shape:  (1613, 16)\n",
      "Test Data: COLOCATED_OPENSTACK.csv\n",
      "Initial data shape:  (2764, 16)\n",
      "-------DT-------\n",
      "Recall: [0.68500539 0.08527132 0.3681178 ]\n",
      "Precision: [0.74136698 0.04421132 0.35134121]\n",
      "f1 score: [0.70933833 0.05915047 0.35411103]\n",
      "-------KNN-------\n",
      "Recall: [0.81121899 0.02325581 0.33674776]\n",
      "Precision: [0.7283293  0.04347826 0.41746032]\n",
      "f1 score: [0.76754274 0.03030303 0.37278526]\n",
      "-------SVM-------\n",
      "Recall: [0.6386192  0.00775194 0.48015365]\n",
      "Precision: [0.72593501 0.02222222 0.34466912]\n",
      "f1 score: [0.6794835  0.01149425 0.40128411]\n",
      "-------NB-------\n",
      "Recall: [0.79665588 0.         0.4084507 ]\n",
      "Precision: [0.73665835 0.         0.43818681]\n",
      "f1 score: [0.76548329 0.         0.42279655]\n",
      "-------RF-------\n",
      "Recall: [0.85544768 0.03100775 0.25800256]\n",
      "Precision: [0.70473562 0.08319039 0.39523677]\n",
      "f1 score: [0.77127269 0.04158587 0.3142232 ]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_MOZILLA.csv') \n",
    "print(\"Train Data: COLOCATED_MOZILLA.csv\")\n",
    "print(\"Initial data shape: \", train_data.shape)\n",
    "train_label = train_data['COLOCATED_STATUS']\n",
    "train_label = convert_label_to_numeric(train_label)\n",
    "train_data = train_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "test_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_OPENSTACK.csv') \n",
    "print(\"Test Data: COLOCATED_OPENSTACK.csv\")\n",
    "print(\"Initial data shape: \", test_data.shape)\n",
    "test_label = test_data['COLOCATED_STATUS']\n",
    "test_label = convert_label_to_numeric(test_label)\n",
    "test_data = test_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "repeated_test(data, true_label,train_data, test_data, train_label, test_label, \"different_file_test\") # repeat cross test 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape:  (1613, 16)\n",
      "Train Data: COLOCATED_MOZILLA.csv\n",
      "Test Data: COLOCATED_WIKIMEDIA.csv\n",
      "Initial data shape:  (2845, 16)\n",
      "-------DT-------\n",
      "Recall: [0.82797505 0.09624413 0.30474453]\n",
      "Precision: [0.79311311 0.10680227 0.35359725]\n",
      "f1 score: [0.80967461 0.09987058 0.33094044]\n",
      "-------KNN-------\n",
      "Recall: [0.91074856 0.03286385 0.24452555]\n",
      "Precision: [0.77755018 0.07368421 0.43365696]\n",
      "f1 score: [0.83889503 0.04545455 0.31271879]\n",
      "-------SVM-------\n",
      "Recall: [0.86900192 0.03755869 0.27919708]\n",
      "Precision: [0.78094006 0.11764706 0.33406114]\n",
      "f1 score: [0.82262094 0.0569395  0.30417495]\n",
      "-------NB-------\n",
      "Recall: [0.89299424 0.02347418 0.34854015]\n",
      "Precision: [0.78324916 0.11904762 0.44730679]\n",
      "f1 score: [0.83452915 0.03921569 0.39179487]\n",
      "-------RF-------\n",
      "Recall: [0.9328215  0.01877934 0.19890511]\n",
      "Precision: [0.76299419 0.09307359 0.44374782]\n",
      "f1 score: [0.83911459 0.03125048 0.27533753]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_MOZILLA.csv') \n",
    "print(\"Initial data shape: \", train_data.shape)\n",
    "print(\"Train Data: COLOCATED_MOZILLA.csv\")\n",
    "train_label = train_data['COLOCATED_STATUS']\n",
    "train_label = convert_label_to_numeric(train_label)\n",
    "train_data = train_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "test_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_WIKIMEDIA.csv') \n",
    "print(\"Test Data: COLOCATED_WIKIMEDIA.csv\")\n",
    "print(\"Initial data shape: \", test_data.shape)\n",
    "test_label = test_data['COLOCATED_STATUS']\n",
    "test_label = convert_label_to_numeric(test_label)\n",
    "test_data = test_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "repeated_test(data, true_label,train_data, test_data, train_label, test_label, \"different_file_test\") # repeat cross test 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: COLOCATED_OPENSTACK.csv\n",
      "Initial data shape:  (2764, 16)\n",
      "Test Data: COLOCATED_MOZILLA.csv\n",
      "Initial data shape:  (1613, 16)\n",
      "-------DT-------\n",
      "Recall: [0.68102797 0.08252427 0.5026738 ]\n",
      "Precision: [0.89465906 0.0472651  0.22117687]\n",
      "f1 score: [0.77424893 0.05994015 0.30736232]\n",
      "-------KNN-------\n",
      "Recall: [0.79516251 0.16504854 0.45989305]\n",
      "Precision: [0.89531915 0.12056738 0.28956229]\n",
      "f1 score: [0.84227382 0.13934426 0.3553719 ]\n",
      "-------SVM-------\n",
      "Recall: [0.83219955 0.00970874 0.61497326]\n",
      "Precision: [0.9017199  0.07692308 0.30343008]\n",
      "f1 score: [0.86556604 0.01724138 0.40636042]\n",
      "-------NB-------\n",
      "Recall: [0.87528345 0.05825243 0.34759358]\n",
      "Precision: [0.86806597 0.21428571 0.25896414]\n",
      "f1 score: [0.87165977 0.09160305 0.29680365]\n",
      "-------RF-------\n",
      "Recall: [0.77588813 0.08737864 0.54545455]\n",
      "Precision: [0.89956906 0.07138957 0.29285329]\n",
      "f1 score: [0.83351331 0.07203664 0.38319365]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_OPENSTACK.csv') \n",
    "print(\"Train Data: COLOCATED_OPENSTACK.csv\")\n",
    "print(\"Initial data shape: \", train_data.shape)\n",
    "train_label = train_data['COLOCATED_STATUS']\n",
    "train_label = convert_label_to_numeric(train_label)\n",
    "train_data = train_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "test_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_MOZILLA.csv') \n",
    "print(\"Test Data: COLOCATED_MOZILLA.csv\")\n",
    "print(\"Initial data shape: \", test_data.shape)\n",
    "test_label = test_data['COLOCATED_STATUS']\n",
    "test_label = convert_label_to_numeric(test_label)\n",
    "test_data = test_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "repeated_test(data, true_label,train_data, test_data, train_label, test_label, \"different_file_test\") # repeat cross test 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: COLOCATED_OPENSTACK.csv\n",
      "Initial data shape:  (2764, 16)\n",
      "Test Data: COLOCATED_WIKIMEDIA.csv\n",
      "Initial data shape:  (2845, 16)\n",
      "-------DT-------\n",
      "Recall: [0.75263916 0.1056338  0.44525547]\n",
      "Precision: [0.80410279 0.11627707 0.34913689]\n",
      "f1 score: [0.77820435 0.11030031 0.39163971]\n",
      "-------KNN-------\n",
      "Recall: [0.82773512 0.03286385 0.47262774]\n",
      "Precision: [0.79676674 0.1147541  0.4184168 ]\n",
      "f1 score: [0.81195575 0.05109489 0.44387318]\n",
      "-------SVM-------\n",
      "Recall: [0.70489443 0.00469484 0.63868613]\n",
      "Precision: [0.82667417 0.04166667 0.33524904]\n",
      "f1 score: [0.76094276 0.00843882 0.43969849]\n",
      "-------NB-------\n",
      "Recall: [0.88771593 0.03755869 0.35948905]\n",
      "Precision: [0.7879046  0.20512821 0.430131  ]\n",
      "f1 score: [0.83483755 0.06349206 0.3916501 ]\n",
      "-------RF-------\n",
      "Recall: [0.83301344 0.0258216  0.42883212]\n",
      "Precision: [0.79405105 0.14236111 0.39090605]\n",
      "f1 score: [0.81365296 0.04240754 0.40941543]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_OPENSTACK.csv') \n",
    "print(\"Train Data: COLOCATED_OPENSTACK.csv\")\n",
    "print(\"Initial data shape: \", train_data.shape)\n",
    "train_label = train_data['COLOCATED_STATUS']\n",
    "train_label = convert_label_to_numeric(train_label)\n",
    "train_data = train_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "test_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_WIKIMEDIA.csv') \n",
    "print(\"Test Data: COLOCATED_WIKIMEDIA.csv\")\n",
    "print(\"Initial data shape: \", test_data.shape)\n",
    "test_label = test_data['COLOCATED_STATUS']\n",
    "test_label = convert_label_to_numeric(test_label)\n",
    "test_data = test_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "repeated_test(data, true_label,train_data, test_data, train_label, test_label, \"different_file_test\") # repeat cross test 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: COLOCATED_WIKIMEDIA.csv\n",
      "Initial data shape:  (2845, 16)\n",
      "Test Data: COLOCATED_MOZILLA.csv\n",
      "Initial data shape:  (1613, 16)\n",
      "-------DT-------\n",
      "Recall: [0.6462585  0.22330097 0.38770053]\n",
      "Precision: [0.86709762 0.07430527 0.23177083]\n",
      "f1 score: [0.74070466 0.1140037  0.293569  ]\n",
      "-------KNN-------\n",
      "Recall: [0.83068783 0.14563107 0.29411765]\n",
      "Precision: [0.85525292 0.07978723 0.39285714]\n",
      "f1 score: [0.84279141 0.10309278 0.33639144]\n",
      "-------SVM-------\n",
      "Recall: [0.81708239 0.09708738 0.64705882]\n",
      "Precision: [0.90764064 0.27027027 0.31428571]\n",
      "f1 score: [0.85998409 0.14285714 0.42307692]\n",
      "-------NB-------\n",
      "Recall: [0.95464853 0.         0.22459893]\n",
      "Precision: [0.84368737 0.         0.36206897]\n",
      "f1 score: [0.89574468 0.         0.27722772]\n",
      "-------RF-------\n",
      "Recall: [0.8733938  0.0776699  0.33957219]\n",
      "Precision: [0.85820986 0.07012527 0.40061728]\n",
      "f1 score: [0.86586504 0.0755716  0.36490237]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_WIKIMEDIA.csv') \n",
    "print(\"Train Data: COLOCATED_WIKIMEDIA.csv\")\n",
    "print(\"Initial data shape: \", train_data.shape)\n",
    "train_label = train_data['COLOCATED_STATUS']\n",
    "train_label = convert_label_to_numeric(train_label)\n",
    "train_data = train_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "test_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_MOZILLA.csv') \n",
    "print(\"Test Data: COLOCATED_MOZILLA.csv\")\n",
    "print(\"Initial data shape: \", test_data.shape)\n",
    "test_label = test_data['COLOCATED_STATUS']\n",
    "test_label = convert_label_to_numeric(test_label)\n",
    "test_data = test_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "repeated_test(data, true_label,train_data, test_data, train_label, test_label, \"different_file_test\") # repeat cross test 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: COLOCATED_WIKIMEDIA.csv\n",
      "Initial data shape:  (2845, 16)\n",
      "Test Data: COLOCATED_OPENSTACK.csv\n",
      "Initial data shape:  (2764, 16)\n",
      "-------DT-------\n",
      "Recall: [0.7877562  0.17054264 0.31241997]\n",
      "Precision: [0.73717215 0.08682588 0.49190071]\n",
      "f1 score: [0.76186736 0.11505647 0.38094193]\n",
      "-------KNN-------\n",
      "Recall: [0.87702265 0.0620155  0.29065301]\n",
      "Precision: [0.7239537  0.0776699  0.54698795]\n",
      "f1 score: [0.79317073 0.06896552 0.37959866]\n",
      "-------SVM-------\n",
      "Recall: [0.77292341 0.00775194 0.47759283]\n",
      "Precision: [0.75699947 0.04545455 0.4393404 ]\n",
      "f1 score: [0.76487857 0.01324503 0.45766871]\n",
      "-------NB-------\n",
      "Recall: [0.8781014  0.00775194 0.35723431]\n",
      "Precision: [0.73300315 0.25       0.51762523]\n",
      "f1 score: [0.7990184  0.01503759 0.42272727]\n",
      "-------RF-------\n",
      "Recall: [0.90884574 0.05426357 0.24327785]\n",
      "Precision: [0.71875461 0.09584699 0.53806135]\n",
      "f1 score: [0.80200105 0.06589267 0.34238769]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_WIKIMEDIA.csv') \n",
    "print(\"Train Data: COLOCATED_WIKIMEDIA.csv\")\n",
    "print(\"Initial data shape: \", train_data.shape)\n",
    "train_label = train_data['COLOCATED_STATUS']\n",
    "train_label = convert_label_to_numeric(train_label)\n",
    "train_data = train_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "test_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_OPENSTACK.csv') \n",
    "print(\"Test Data: COLOCATED_OPENSTACK.csv\")\n",
    "print(\"Initial data shape: \", test_data.shape)\n",
    "test_label = test_data['COLOCATED_STATUS']\n",
    "test_label = convert_label_to_numeric(test_label)\n",
    "test_data = test_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "repeated_test(data, true_label,train_data, test_data, train_label, test_label, \"different_file_test\") # repeat cross test 10 times and report avarage performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
