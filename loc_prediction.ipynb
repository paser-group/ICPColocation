{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm, tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_file (filename):\n",
    "    df = pd.read_csv(filename)  # read the csv file\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_to_numeric(label):\n",
    "    converted_label = np.empty(len(label), dtype=object) \n",
    "    for i in range(len(label)):\n",
    "        if label[i] == \"ONLY_ONE\":\n",
    "            converted_label[i] = 1\n",
    "        elif label[i] == \"NEUTRAL\":\n",
    "            converted_label[i] = 0\n",
    "        else: \n",
    "            converted_label[i] = 2\n",
    "    converted_label = converted_label.astype('int')\n",
    "    return converted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_PCA(train, test):\n",
    "    # Since PCA is effected by scale, we need to scale the features in the data before applying PCA\n",
    "    scaler = StandardScaler()\n",
    "    # Fit on training set only.\n",
    "    scaler.fit(train)\n",
    "    # Apply transform to both the training set and the test set.\n",
    "    train = scaler.transform(train)\n",
    "    test = scaler.transform(test)\n",
    "\n",
    "    # Make an instance of the Model\n",
    "    pca = PCA(.95) #  choose the minimum number of principal components such that 95% of the variance is retained.\n",
    "    # We are fitting PCA on the training set only.\n",
    "    pca.fit(train)\n",
    "    print (\"Number of selected components: \", pca.n_components_)\n",
    "    #print (pd.DataFrame(pca.components_))\n",
    "    \n",
    "    # Apply the mapping (transform) to both the training set and the test set\n",
    "    print(\"Before applying PCA train set size: \", train.shape)\n",
    "    print(\"Before applying PCA test set size: \", test.shape)\n",
    "    train = pca.transform(train)\n",
    "    test = pca.transform(test)\n",
    "    print(\"After applying PCA train set size: \", train.shape)\n",
    "    print(\"After applying PCA test set size: \", test.shape)\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance(true_label, predicted_label):   \n",
    "    report = classification_report(true_label, predicted_label, digits=3)\n",
    "    recall = recall_score(true_label, predicted_label, average=\"macro\")\n",
    "    precision = precision_score(true_label, predicted_label, average=\"macro\")\n",
    "    f1 = f1_score(true_label, predicted_label, average=\"macro\")\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape:  (1613, 16)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_MOZILLA.csv') \n",
    "print(\"Initial data shape: \", data.shape)\n",
    "true_label = data['COLOCATED_STATUS']\n",
    "true_label = convert_label_to_numeric(true_label)\n",
    "data = data['SLOC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 fold cv\n",
    "kf = KFold(n_splits=10, shuffle = True, random_state = 7)\n",
    "\n",
    "cv_recall_DT = []\n",
    "cv_precision_DT = []\n",
    "cv_f1_DT = []\n",
    "\n",
    "cv_recall_KNN = []\n",
    "cv_precision_KNN = []\n",
    "cv_f1_KNN = []\n",
    "\n",
    "cv_recall_SVM = []\n",
    "cv_precision_SVM = []\n",
    "cv_f1_SVM = []\n",
    "\n",
    "cv_recall_NB = []\n",
    "cv_precision_NB = []\n",
    "cv_f1_NB = []\n",
    "\n",
    "cv_recall_RF = []\n",
    "cv_precision_RF = []\n",
    "cv_f1_RF = []\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    train, test = data.loc[train_index], data.loc[test_index]\n",
    "    train_label, test_label = true_label[train_index], true_label[test_index]\n",
    "    \n",
    "    train = train.values.reshape(-1, 1)\n",
    "    test = test.values.reshape(-1, 1)\n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    cv_recall_DT.append(recall)\n",
    "    cv_precision_DT.append(precision)\n",
    "    cv_f1_DT.append(f1)\n",
    "    \n",
    "    clf = KNeighborsClassifier(n_neighbors=3)\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    cv_recall_KNN.append(recall)\n",
    "    cv_precision_KNN.append(precision)\n",
    "    cv_f1_KNN.append(f1)\n",
    "    \n",
    "    clf = svm.SVC(gamma='scale')\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    cv_recall_SVM.append(recall)\n",
    "    cv_precision_SVM.append(precision)\n",
    "    cv_f1_SVM.append(f1)\n",
    "\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    cv_recall_NB.append(recall)\n",
    "    cv_precision_NB.append(precision)\n",
    "    cv_f1_NB.append(f1)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    cv_recall_RF.append(recall)\n",
    "    cv_precision_RF.append(precision)\n",
    "    cv_f1_RF.append(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------DT-------\n",
      "Recall: 0.41572713442997034\n",
      "Precision: 0.5110221674627832\n",
      "f1 score: 0.43338684199058025\n",
      "-------KNN-------\n",
      "Recall: 0.4201736149395203\n",
      "Precision: 0.45381536911039266\n",
      "f1 score: 0.42567244064674375\n",
      "-------SVM-------\n",
      "Recall: 0.3887258183883073\n",
      "Precision: 0.46102260946146323\n",
      "f1 score: 0.38933558634212195\n",
      "-------NB-------\n",
      "Recall: 0.4037389152735341\n",
      "Precision: 0.46421021410340524\n",
      "f1 score: 0.40853637290801226\n",
      "-------RF-------\n",
      "Recall: 0.4081902412090595\n",
      "Precision: 0.4423054674280216\n",
      "f1 score: 0.40851125877127875\n"
     ]
    }
   ],
   "source": [
    "print(\"-------DT-------\")\n",
    "print(\"Recall:\", np.mean(cv_recall_DT))\n",
    "print(\"Precision:\", np.mean(cv_precision_DT))\n",
    "print(\"f1 score:\", np.mean(cv_f1_DT))\n",
    "\n",
    "print(\"-------KNN-------\")\n",
    "print(\"Recall:\", np.mean(cv_recall_KNN))\n",
    "print(\"Precision:\", np.mean(cv_precision_KNN))\n",
    "print(\"f1 score:\", np.mean(cv_f1_KNN))\n",
    "\n",
    "print(\"-------SVM-------\")\n",
    "print(\"Recall:\", np.mean(cv_recall_SVM))\n",
    "print(\"Precision:\", np.mean(cv_precision_SVM))\n",
    "print(\"f1 score:\", np.mean(cv_f1_SVM))\n",
    "\n",
    "print(\"-------NB-------\")\n",
    "print(\"Recall:\", np.mean(cv_recall_NB))\n",
    "print(\"Precision:\", np.mean(cv_precision_NB))\n",
    "print(\"f1 score:\", np.mean(cv_f1_NB))\n",
    "\n",
    "print(\"-------RF-------\")\n",
    "print(\"Recall:\", np.mean(cv_recall_RF))\n",
    "print(\"Precision:\", np.mean(cv_precision_RF))\n",
    "print(\"f1 score:\", np.mean(cv_f1_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
