{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm, tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_file (filename):\n",
    "    df = pd.read_csv(filename)  # read the csv file\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_to_numeric(label):\n",
    "    converted_label = np.empty(len(label), dtype=object) \n",
    "    for i in range(len(label)):\n",
    "        if label[i] == \"ONLY_ONE\":\n",
    "            converted_label[i] = 1\n",
    "        elif label[i] == \"NEUTRAL\":\n",
    "            converted_label[i] = 0\n",
    "        else: \n",
    "            converted_label[i] = 2\n",
    "    converted_label = converted_label.astype('int')\n",
    "    return converted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_PCA(train, test):\n",
    "    # Since PCA is effected by scale, we need to scale the features in the data before applying PCA\n",
    "    scaler = StandardScaler()\n",
    "    # Fit on training set only.\n",
    "    scaler.fit(train)\n",
    "    # Apply transform to both the training set and the test set.\n",
    "    train = scaler.transform(train)\n",
    "    test = scaler.transform(test)\n",
    "\n",
    "    # Make an instance of the Model\n",
    "    pca = PCA(.95) #  choose the minimum number of principal components such that 95% of the variance is retained.\n",
    "    # We are fitting PCA on the training set only.\n",
    "    pca.fit(train)\n",
    "    #print (\"Number of selected components: \", pca.n_components_)\n",
    "    #print (pd.DataFrame(pca.components_))\n",
    "    \n",
    "    # Apply the mapping (transform) to both the training set and the test set\n",
    "    #print(\"Before applying PCA train set size: \", train.shape)\n",
    "    #print(\"Before applying PCA test set size: \", test.shape)\n",
    "    train = pca.transform(train)\n",
    "    test = pca.transform(test)\n",
    "    #print(\"After applying PCA train set size: \", train.shape)\n",
    "    #print(\"After applying PCA test set size: \", test.shape)\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_CART(train, test, train_label, test_label):\n",
    "    clf = tree.DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                                      min_samples_split = 2, min_weight_fraction_leaf=0.0)\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_KNN(train, test, train_label, test_label):\n",
    "    clf = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_SVM(train, test, train_label, test_label):\n",
    "    clf = svm.SVC(gamma='auto', C = 20.0, kernel='rbf', class_weight = {0:1, 1:1, 2:5})\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_NB(train, test, train_label, test_label):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_RF(train, test, train_label, test_label):\n",
    "    clf = RandomForestClassifier(n_estimators=10, criterion='gini')\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance(true_label, predicted_label):   \n",
    "    report = classification_report(true_label, predicted_label, digits=3)\n",
    "    recall = recall_score(true_label, predicted_label, average=\"macro\")\n",
    "    precision = precision_score(true_label, predicted_label, average=\"macro\")\n",
    "    f1 = f1_score(true_label, predicted_label, average=\"macro\")\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cv(data, true_label):\n",
    "    # 10 fold cv\n",
    "    kf = KFold(n_splits=10, shuffle = True, random_state = 7)\n",
    "\n",
    "    cv_recall_DT = []\n",
    "    cv_precision_DT = []\n",
    "    cv_f1_DT = []\n",
    "\n",
    "    cv_recall_KNN = []\n",
    "    cv_precision_KNN = []\n",
    "    cv_f1_KNN = []\n",
    "\n",
    "    cv_recall_SVM = []\n",
    "    cv_precision_SVM = []\n",
    "    cv_f1_SVM = []\n",
    "\n",
    "    cv_recall_NB = []\n",
    "    cv_precision_NB = []\n",
    "    cv_f1_NB = []\n",
    "\n",
    "    cv_recall_RF = []\n",
    "    cv_precision_RF = []\n",
    "    cv_f1_RF = []\n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train, test = data.loc[train_index], data.loc[test_index]\n",
    "        train_label, test_label = true_label[train_index], true_label[test_index]\n",
    "\n",
    "        train, test = apply_PCA(train, test)\n",
    "\n",
    "        recall, precision, f1 = perfrom_CART(train, test, train_label, test_label)\n",
    "        cv_recall_DT.append(recall)\n",
    "        cv_precision_DT.append(precision)\n",
    "        cv_f1_DT.append(f1)\n",
    "\n",
    "        recall, precision, f1 = perfrom_KNN(train, test, train_label, test_label)\n",
    "        cv_recall_KNN.append(recall)\n",
    "        cv_precision_KNN.append(precision)\n",
    "        cv_f1_KNN.append(f1)\n",
    "\n",
    "        recall, precision, f1 = perfrom_SVM(train, test, train_label, test_label)\n",
    "        cv_recall_SVM.append(recall)\n",
    "        cv_precision_SVM.append(precision)\n",
    "        cv_f1_SVM.append(f1)\n",
    "\n",
    "        recall, precision, f1 = perfrom_NB(train, test, train_label, test_label)\n",
    "        cv_recall_NB.append(recall)\n",
    "        cv_precision_NB.append(precision)\n",
    "        cv_f1_NB.append(f1)\n",
    "\n",
    "        recall, precision, f1 = perfrom_RF(train, test, train_label, test_label)\n",
    "        cv_recall_RF.append(recall)\n",
    "        cv_precision_RF.append(precision)\n",
    "        cv_f1_RF.append(f1)\n",
    "\n",
    "        \n",
    "    recall_DT = np.mean(cv_recall_DT)\n",
    "    precision_DT = np.mean(cv_precision_DT)\n",
    "    f1_DT = np.mean(cv_f1_DT)\n",
    "\n",
    "    recall_KNN = np.mean(cv_recall_KNN)\n",
    "    precision_KNN = np.mean(cv_precision_KNN)\n",
    "    f1_KNN = np.mean(cv_f1_KNN)\n",
    "\n",
    "    recall_SVM = np.mean(cv_recall_SVM)\n",
    "    precision_SVM = np.mean(cv_precision_SVM)\n",
    "    f1_SVM =  np.mean(cv_f1_SVM)\n",
    "\n",
    "    recall_NB = np.mean(cv_recall_NB)\n",
    "    precision_NB = np.mean(cv_precision_NB)\n",
    "    f1_NB = np.mean(cv_f1_NB)\n",
    "\n",
    "    recall_RF = np.mean(cv_recall_RF)\n",
    "    precision_RF = np.mean(cv_precision_RF)\n",
    "    f1_RF = np.mean(cv_f1_RF)\n",
    "    \n",
    "    return recall_DT, precision_DT, f1_DT, recall_KNN, precision_KNN, f1_KNN, recall_SVM, precision_SVM,\\\n",
    "    f1_SVM, recall_NB, precision_NB, f1_NB, recall_RF, precision_RF, f1_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def different_file_test(train, test, train_label, test_label):\n",
    "    \n",
    "    train, test = apply_PCA(train, test)\n",
    "        \n",
    "    recall_DT, precision_DT, f1_DT = perfrom_CART(train, test, train_label, test_label)\n",
    "    recall_KNN, precision_KNN, f1_KNN = perfrom_KNN(train, test, train_label, test_label)\n",
    "    recall_SVM, precision_SVM, f1_SVM = perfrom_SVM(train, test, train_label, test_label)\n",
    "    recall_NB, precision_NB, f1_NB = perfrom_NB(train, test, train_label, test_label)\n",
    "    recall_RF, precision_RF, f1_RF = perfrom_RF(train, test, train_label, test_label)\n",
    "\n",
    "    return recall_DT, precision_DT, f1_DT, recall_KNN, precision_KNN, f1_KNN, recall_SVM, precision_SVM,\\\n",
    "    f1_SVM, recall_NB, precision_NB, f1_NB, recall_RF, precision_RF, f1_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_test(data, true_label, train_data, test_data, train_label, test_label, test_name):\n",
    "    repeated_recall_DT = []\n",
    "    repeated_precision_DT = []\n",
    "    repeated_f1_DT = []\n",
    "\n",
    "    repeated_recall_KNN = []\n",
    "    repeated_precision_KNN = []\n",
    "    repeated_f1_KNN = []\n",
    "\n",
    "    repeated_recall_SVM = []\n",
    "    repeated_precision_SVM = []\n",
    "    repeated_f1_SVM = []\n",
    "\n",
    "    repeated_recall_NB = []\n",
    "    repeated_precision_NB = []\n",
    "    repeated_f1_NB = []\n",
    "\n",
    "    repeated_recall_RF = []\n",
    "    repeated_precision_RF = []\n",
    "    repeated_f1_RF = []\n",
    "    \n",
    "    recall_DT= precision_DT= f1_DT= recall_KNN= precision_KNN= f1_KNN= recall_SVM= precision_SVM= f1_SVM\\\n",
    "    = recall_NB= precision_NB= f1_NB= recall_RF= precision_RF= f1_RF = 0\n",
    "    \n",
    "    for i in range(10):\n",
    "        if test_name == \"k_fold\":\n",
    "            recall_DT, precision_DT, f1_DT, recall_KNN, precision_KNN, f1_KNN, recall_SVM, precision_SVM, f1_SVM,\\\n",
    "            recall_NB, precision_NB, f1_NB, recall_RF, precision_RF, f1_RF = kfold_cv(data, true_label)\n",
    "        else: \n",
    "            recall_DT, precision_DT, f1_DT, recall_KNN, precision_KNN, f1_KNN, recall_SVM, precision_SVM, f1_SVM,\\\n",
    "            recall_NB, precision_NB, f1_NB, recall_RF, precision_RF, f1_RF = different_file_test(train_data, test_data, train_label, test_label)\n",
    "        \n",
    "        repeated_recall_DT.append(recall_DT)\n",
    "        repeated_precision_DT.append(precision_DT)\n",
    "        repeated_f1_DT.append(f1_DT)\n",
    "\n",
    "        repeated_recall_KNN.append(recall_KNN)\n",
    "        repeated_precision_KNN.append(precision_KNN)\n",
    "        repeated_f1_KNN.append(f1_KNN)\n",
    "\n",
    "        repeated_recall_SVM.append(recall_SVM)\n",
    "        repeated_precision_SVM.append(precision_SVM)\n",
    "        repeated_f1_SVM.append(f1_SVM)\n",
    "\n",
    "        repeated_recall_NB.append(recall_NB)\n",
    "        repeated_precision_NB.append(precision_NB)\n",
    "        repeated_f1_NB.append(f1_NB)\n",
    "\n",
    "        repeated_recall_RF.append(recall_RF)\n",
    "        repeated_precision_RF.append(precision_RF)\n",
    "        repeated_f1_RF.append(f1_RF)\n",
    "        \n",
    "    print(\"-------DT-------\")\n",
    "    print(\"Recall:\", np.mean(repeated_recall_DT))\n",
    "    print(\"Precision:\", np.mean(repeated_precision_DT))\n",
    "    print(\"f1 score:\", np.mean(repeated_f1_DT))\n",
    "\n",
    "    print(\"-------KNN-------\")\n",
    "    print(\"Recall:\", np.mean(repeated_recall_KNN))\n",
    "    print(\"Precision:\", np.mean(repeated_precision_KNN))\n",
    "    print(\"f1 score:\", np.mean(repeated_f1_KNN))\n",
    "\n",
    "    print(\"-------SVM-------\")\n",
    "    print(\"Recall:\", np.mean(repeated_recall_SVM))\n",
    "    print(\"Precision:\", np.mean(repeated_precision_SVM))\n",
    "    print(\"f1 score:\", np.mean(repeated_f1_SVM))\n",
    "\n",
    "    print(\"-------NB-------\")\n",
    "    print(\"Recall:\", np.mean(repeated_recall_NB))\n",
    "    print(\"Precision:\", np.mean(repeated_precision_NB))\n",
    "    print(\"f1 score:\", np.mean(repeated_f1_NB))\n",
    "\n",
    "    print(\"-------RF-------\")\n",
    "    print(\"Recall:\", np.mean(repeated_recall_RF))\n",
    "    print(\"Precision:\", np.mean(repeated_precision_RF))\n",
    "    print(\"f1 score:\", np.mean(repeated_f1_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcFeatureImp(feature_vec, label_vec, feature_names_param, repeat=10):\n",
    "    header_str, output= '', ''\n",
    "    for name_ in feature_names_param:\n",
    "        header_str = header_str + name_ + ','\n",
    "    theRndForestModel = RandomForestClassifier()\n",
    "    theRndForestModel.fit(feature_vec, label_vec)\n",
    "    feat_imp_vector=theRndForestModel.feature_importances_\n",
    "\n",
    "    for ind_ in range(repeat):\n",
    "        for imp_vec_index in range(len(feat_imp_vector)):\n",
    "            feat_imp_val = round(feat_imp_vector[imp_vec_index], 5)\n",
    "            output = output +  str(feat_imp_val) + ','\n",
    "        output = output + '\\n'\n",
    "    output_status = header_str + '\\n' + output\n",
    "    print (\"Feature importance: \", output_status)\n",
    "    \n",
    "    feat_imp_vector=list(feat_imp_vector)\n",
    "    sorted_feat_imp_vector= [x_ for x_ in feat_imp_vector]\n",
    "    sorted_feat_imp_vector.sort(reverse=True)\n",
    "    \n",
    "    sorted_feature_name = []\n",
    "    for feat_imp_val in sorted_feat_imp_vector:\n",
    "        feat_index = feat_imp_vector.index(feat_imp_val) \n",
    "        sorted_feature_name.append(feature_names_param[feat_index])\n",
    "        \n",
    "    print (\"sorted feature names: \", sorted_feature_name)\n",
    "    print (\"sorted feature importance: \", sorted_feat_imp_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, true_label, train_data, test_data, train_label, test_label = [], [], [], [], [], [] # necessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set: COLOCATED_MOZILLA.csv\n",
      "Initial data shape:  (1613, 16)\n",
      "-------DT-------\n",
      "Recall: 0.8921702490935939\n",
      "Precision: 0.8525936624569133\n",
      "f1 score: 0.8646163631410444\n",
      "-------KNN-------\n",
      "Recall: 0.8996578000728326\n",
      "Precision: 0.9078891938789528\n",
      "f1 score: 0.9009914677819351\n",
      "-------SVM-------\n",
      "Recall: 0.6927078668314843\n",
      "Precision: 0.7713794250479379\n",
      "f1 score: 0.7034100740450092\n",
      "-------NB-------\n",
      "Recall: 0.4417971611795387\n",
      "Precision: 0.4819069337609035\n",
      "f1 score: 0.4465596739043945\n",
      "-------RF-------\n",
      "Recall: 0.8360641469006354\n",
      "Precision: 0.9048397114158728\n",
      "f1 score: 0.8612799464473604\n",
      "Feature importance:  ATTR,CMD,COMMENT,ENS,FILE,FILE_MODE,HARD_CODE,INCL,SLOC,REQ,SSH,URL,\n",
      "0.1519,0.04661,0.06295,0.06172,0.0411,0.03549,0.15897,0.07233,0.21496,0.04671,0.0,0.10726,\n",
      "0.1519,0.04661,0.06295,0.06172,0.0411,0.03549,0.15897,0.07233,0.21496,0.04671,0.0,0.10726,\n",
      "0.1519,0.04661,0.06295,0.06172,0.0411,0.03549,0.15897,0.07233,0.21496,0.04671,0.0,0.10726,\n",
      "0.1519,0.04661,0.06295,0.06172,0.0411,0.03549,0.15897,0.07233,0.21496,0.04671,0.0,0.10726,\n",
      "0.1519,0.04661,0.06295,0.06172,0.0411,0.03549,0.15897,0.07233,0.21496,0.04671,0.0,0.10726,\n",
      "0.1519,0.04661,0.06295,0.06172,0.0411,0.03549,0.15897,0.07233,0.21496,0.04671,0.0,0.10726,\n",
      "0.1519,0.04661,0.06295,0.06172,0.0411,0.03549,0.15897,0.07233,0.21496,0.04671,0.0,0.10726,\n",
      "0.1519,0.04661,0.06295,0.06172,0.0411,0.03549,0.15897,0.07233,0.21496,0.04671,0.0,0.10726,\n",
      "0.1519,0.04661,0.06295,0.06172,0.0411,0.03549,0.15897,0.07233,0.21496,0.04671,0.0,0.10726,\n",
      "0.1519,0.04661,0.06295,0.06172,0.0411,0.03549,0.15897,0.07233,0.21496,0.04671,0.0,0.10726,\n",
      "\n",
      "sorted feature names:  ['SLOC', 'HARD_CODE', 'ATTR', 'URL', 'INCL', 'COMMENT', 'ENS', 'REQ', 'CMD', 'FILE', 'FILE_MODE', 'SSH']\n",
      "sorted feature importance:  [0.21495581343614237, 0.15897053249299517, 0.15190346278508698, 0.10725622770640687, 0.07232869364496289, 0.06294943190495358, 0.061724187616905575, 0.0467122233432482, 0.046608666906762616, 0.04109688374162387, 0.03549387642091187, 0.0]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_MOZILLA.csv') \n",
    "print(\"Data set: COLOCATED_MOZILLA.csv\")\n",
    "print(\"Initial data shape: \", data.shape)\n",
    "true_label = data['COLOCATED_STATUS']\n",
    "true_label = convert_label_to_numeric(true_label)\n",
    "data = data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "repeated_test(data, true_label, train_data, test_data, train_label, test_label, \"k_fold\") #repeat kfold 10 times and report avarage performance\n",
    "\n",
    "columns_name = list(data.columns.values) # read all column names\n",
    "calcFeatureImp(data, true_label, columns_name) # find feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set: COLOCATED_OPENSTACK.csv\n",
      "Initial data shape:  (2764, 16)\n",
      "-------DT-------\n",
      "Recall: 0.5472283053430641\n",
      "Precision: 0.5471290144163452\n",
      "f1 score: 0.5440285223938526\n",
      "-------KNN-------\n",
      "Recall: 0.5465068504006748\n",
      "Precision: 0.584485381016399\n",
      "f1 score: 0.5506136828988317\n",
      "-------SVM-------\n",
      "Recall: 0.526456027178722\n",
      "Precision: 0.49377690310870676\n",
      "f1 score: 0.49004672608296546\n",
      "-------NB-------\n",
      "Recall: 0.44290181209010504\n",
      "Precision: 0.5589356550283747\n",
      "f1 score: 0.45351203595714445\n",
      "-------RF-------\n",
      "Recall: 0.547854274557287\n",
      "Precision: 0.6012433317003287\n",
      "f1 score: 0.5563066346355872\n",
      "Feature importance:  ATTR,CMD,COMMENT,ENS,FILE,FILE_MODE,HARD_CODE,INCL,SLOC,REQ,SSH,URL,\n",
      "0.16583,0.02906,0.1229,0.0568,0.02524,0.0189,0.22136,0.05156,0.1599,0.03858,0.00021,0.10966,\n",
      "0.16583,0.02906,0.1229,0.0568,0.02524,0.0189,0.22136,0.05156,0.1599,0.03858,0.00021,0.10966,\n",
      "0.16583,0.02906,0.1229,0.0568,0.02524,0.0189,0.22136,0.05156,0.1599,0.03858,0.00021,0.10966,\n",
      "0.16583,0.02906,0.1229,0.0568,0.02524,0.0189,0.22136,0.05156,0.1599,0.03858,0.00021,0.10966,\n",
      "0.16583,0.02906,0.1229,0.0568,0.02524,0.0189,0.22136,0.05156,0.1599,0.03858,0.00021,0.10966,\n",
      "0.16583,0.02906,0.1229,0.0568,0.02524,0.0189,0.22136,0.05156,0.1599,0.03858,0.00021,0.10966,\n",
      "0.16583,0.02906,0.1229,0.0568,0.02524,0.0189,0.22136,0.05156,0.1599,0.03858,0.00021,0.10966,\n",
      "0.16583,0.02906,0.1229,0.0568,0.02524,0.0189,0.22136,0.05156,0.1599,0.03858,0.00021,0.10966,\n",
      "0.16583,0.02906,0.1229,0.0568,0.02524,0.0189,0.22136,0.05156,0.1599,0.03858,0.00021,0.10966,\n",
      "0.16583,0.02906,0.1229,0.0568,0.02524,0.0189,0.22136,0.05156,0.1599,0.03858,0.00021,0.10966,\n",
      "\n",
      "sorted feature names:  ['HARD_CODE', 'ATTR', 'SLOC', 'COMMENT', 'URL', 'ENS', 'INCL', 'REQ', 'CMD', 'FILE', 'FILE_MODE', 'SSH']\n",
      "sorted feature importance:  [0.22135968108313148, 0.16582695702720732, 0.1599049502065278, 0.1228968646072731, 0.109657209177621, 0.05679521207913394, 0.05156209863841771, 0.038581438847363814, 0.029062625195810484, 0.02523704446076669, 0.018903448177839604, 0.00021247049890707692]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_OPENSTACK.csv') \n",
    "print(\"Data set: COLOCATED_OPENSTACK.csv\")\n",
    "print(\"Initial data shape: \", data.shape)\n",
    "true_label = data['COLOCATED_STATUS']\n",
    "true_label = convert_label_to_numeric(true_label)\n",
    "data = data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "repeated_test(data, true_label, train_data, test_data, train_label, test_label, \"k_fold\") #repeat kfold 10 times and report avarage performance\n",
    "\n",
    "columns_name = list(data.columns.values) # read all column names\n",
    "calcFeatureImp(data, true_label, columns_name) # find feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set: COLOCATED_WIKIMEDIA.csv\n",
      "Initial data shape:  (2845, 16)\n",
      "-------DT-------\n",
      "Recall: 0.47143406805849253\n",
      "Precision: 0.4725381409905565\n",
      "f1 score: 0.4700542752262421\n",
      "-------KNN-------\n",
      "Recall: 0.4806062104426288\n",
      "Precision: 0.5453234342467559\n",
      "f1 score: 0.49502956109292817\n",
      "-------SVM-------\n",
      "Recall: 0.46268595417217817\n",
      "Precision: 0.41064505883862407\n",
      "f1 score: 0.4159924656348165\n",
      "-------NB-------\n",
      "Recall: 0.40259497439713093\n",
      "Precision: 0.44428341807287347\n",
      "f1 score: 0.4023032320496731\n",
      "-------RF-------\n",
      "Recall: 0.46080062940421573\n",
      "Precision: 0.5512580768161573\n",
      "f1 score: 0.47382136252823726\n",
      "Feature importance:  ATTR,CMD,COMMENT,ENS,FILE,FILE_MODE,HARD_CODE,INCL,SLOC,REQ,SSH,URL,\n",
      "0.15489,0.05392,0.12956,0.06351,0.0463,0.03872,0.15071,0.05525,0.21239,0.04954,0.00016,0.04505,\n",
      "0.15489,0.05392,0.12956,0.06351,0.0463,0.03872,0.15071,0.05525,0.21239,0.04954,0.00016,0.04505,\n",
      "0.15489,0.05392,0.12956,0.06351,0.0463,0.03872,0.15071,0.05525,0.21239,0.04954,0.00016,0.04505,\n",
      "0.15489,0.05392,0.12956,0.06351,0.0463,0.03872,0.15071,0.05525,0.21239,0.04954,0.00016,0.04505,\n",
      "0.15489,0.05392,0.12956,0.06351,0.0463,0.03872,0.15071,0.05525,0.21239,0.04954,0.00016,0.04505,\n",
      "0.15489,0.05392,0.12956,0.06351,0.0463,0.03872,0.15071,0.05525,0.21239,0.04954,0.00016,0.04505,\n",
      "0.15489,0.05392,0.12956,0.06351,0.0463,0.03872,0.15071,0.05525,0.21239,0.04954,0.00016,0.04505,\n",
      "0.15489,0.05392,0.12956,0.06351,0.0463,0.03872,0.15071,0.05525,0.21239,0.04954,0.00016,0.04505,\n",
      "0.15489,0.05392,0.12956,0.06351,0.0463,0.03872,0.15071,0.05525,0.21239,0.04954,0.00016,0.04505,\n",
      "0.15489,0.05392,0.12956,0.06351,0.0463,0.03872,0.15071,0.05525,0.21239,0.04954,0.00016,0.04505,\n",
      "\n",
      "sorted feature names:  ['SLOC', 'ATTR', 'HARD_CODE', 'COMMENT', 'ENS', 'INCL', 'CMD', 'REQ', 'FILE', 'URL', 'FILE_MODE', 'SSH']\n",
      "sorted feature importance:  [0.21239067571621445, 0.1548942638027534, 0.1507113775309594, 0.12955608301344365, 0.06350515128025806, 0.05525291140663035, 0.05391801684035136, 0.04953963109295937, 0.04630278348236443, 0.04505017710873673, 0.03871581807825945, 0.0001631106470692622]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_WIKIMEDIA.csv') \n",
    "print(\"Data set: COLOCATED_WIKIMEDIA.csv\")\n",
    "print(\"Initial data shape: \", data.shape)\n",
    "true_label = data['COLOCATED_STATUS']\n",
    "true_label = convert_label_to_numeric(true_label)\n",
    "data = data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "repeated_test(data, true_label, train_data, test_data, train_label, test_label, \"k_fold\") # repeat kfold 10 times and report avarage performance\n",
    "\n",
    "columns_name = list(data.columns.values) # read all column names\n",
    "calcFeatureImp(data, true_label, columns_name) # find feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: COLOCATED_MOZILLA.csv\n",
      "Initial data shape:  (1613, 16)\n",
      "Test Data: COLOCATED_OPENSTACK.csv\n",
      "Initial data shape:  (2764, 16)\n",
      "-------DT-------\n",
      "Recall: 0.37508148969611355\n",
      "Precision: 0.3767070067586887\n",
      "f1 score: 0.3717533142977103\n",
      "-------KNN-------\n",
      "Recall: 0.3904075197375755\n",
      "Precision: 0.39642262538356865\n",
      "f1 score: 0.39021034315994685\n",
      "-------SVM-------\n",
      "Recall: 0.37550826295940926\n",
      "Precision: 0.3642754496886976\n",
      "f1 score: 0.364087287580067\n",
      "-------NB-------\n",
      "Recall: 0.4017021944685011\n",
      "Precision: 0.3916150557671755\n",
      "f1 score: 0.39609327994487364\n",
      "-------RF-------\n",
      "Recall: 0.372148158298658\n",
      "Precision: 0.3808089469438597\n",
      "f1 score: 0.3685750075257793\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_MOZILLA.csv') \n",
    "print(\"Train Data: COLOCATED_MOZILLA.csv\")\n",
    "print(\"Initial data shape: \", train_data.shape)\n",
    "train_label = train_data['COLOCATED_STATUS']\n",
    "train_label = convert_label_to_numeric(train_label)\n",
    "train_data = train_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "test_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_OPENSTACK.csv') \n",
    "print(\"Test Data: COLOCATED_OPENSTACK.csv\")\n",
    "print(\"Initial data shape: \", test_data.shape)\n",
    "test_label = test_data['COLOCATED_STATUS']\n",
    "test_label = convert_label_to_numeric(test_label)\n",
    "test_data = test_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "repeated_test(data, true_label,train_data, test_data, train_label, test_label, \"different_file_test\") # repeat cross test 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape:  (1613, 16)\n",
      "Train Data: COLOCATED_MOZILLA.csv\n",
      "Test Data: COLOCATED_WIKIMEDIA.csv\n",
      "Initial data shape:  (2845, 16)\n",
      "-------DT-------\n",
      "Recall: 0.4060680752818088\n",
      "Precision: 0.41409165490775546\n",
      "f1 score: 0.4088130324795066\n",
      "-------KNN-------\n",
      "Recall: 0.3960459858903888\n",
      "Precision: 0.42829711760193145\n",
      "f1 score: 0.3990227865144219\n",
      "-------SVM-------\n",
      "Recall: 0.3952525617079256\n",
      "Precision: 0.4108827515218526\n",
      "f1 score: 0.3945784641151898\n",
      "-------NB-------\n",
      "Recall: 0.4216695220772559\n",
      "Precision: 0.4498678562886213\n",
      "f1 score: 0.4218465686838148\n",
      "-------RF-------\n",
      "Recall: 0.3851404737694794\n",
      "Precision: 0.4473957870720421\n",
      "f1 score: 0.38271055698195233\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_MOZILLA.csv') \n",
    "print(\"Initial data shape: \", train_data.shape)\n",
    "print(\"Train Data: COLOCATED_MOZILLA.csv\")\n",
    "train_label = train_data['COLOCATED_STATUS']\n",
    "train_label = convert_label_to_numeric(train_label)\n",
    "train_data = train_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "test_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_WIKIMEDIA.csv') \n",
    "print(\"Test Data: COLOCATED_WIKIMEDIA.csv\")\n",
    "print(\"Initial data shape: \", test_data.shape)\n",
    "test_label = test_data['COLOCATED_STATUS']\n",
    "test_label = convert_label_to_numeric(test_label)\n",
    "test_data = test_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "repeated_test(data, true_label,train_data, test_data, train_label, test_label, \"different_file_test\") # repeat cross test 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: COLOCATED_OPENSTACK.csv\n",
      "Initial data shape:  (2764, 16)\n",
      "Test Data: COLOCATED_MOZILLA.csv\n",
      "Initial data shape:  (1613, 16)\n",
      "-------DT-------\n",
      "Recall: 0.4271158707018488\n",
      "Precision: 0.3907769866352669\n",
      "f1 score: 0.38321572644105845\n",
      "-------KNN-------\n",
      "Recall: 0.4733680337552954\n",
      "Precision: 0.43514960479499487\n",
      "f1 score: 0.44566332739225756\n",
      "-------SVM-------\n",
      "Recall: 0.4856271821271413\n",
      "Precision: 0.42735768593288376\n",
      "f1 score: 0.4297226136914875\n",
      "-------NB-------\n",
      "Recall: 0.4270431522613949\n",
      "Precision: 0.4471052749095003\n",
      "f1 score: 0.4200221576857574\n",
      "-------RF-------\n",
      "Recall: 0.47879674507179876\n",
      "Precision: 0.4328761626595097\n",
      "f1 score: 0.44162918924661465\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_OPENSTACK.csv') \n",
    "print(\"Train Data: COLOCATED_OPENSTACK.csv\")\n",
    "print(\"Initial data shape: \", train_data.shape)\n",
    "train_label = train_data['COLOCATED_STATUS']\n",
    "train_label = convert_label_to_numeric(train_label)\n",
    "train_data = train_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "test_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_MOZILLA.csv') \n",
    "print(\"Test Data: COLOCATED_MOZILLA.csv\")\n",
    "print(\"Initial data shape: \", test_data.shape)\n",
    "test_label = test_data['COLOCATED_STATUS']\n",
    "test_label = convert_label_to_numeric(test_label)\n",
    "test_data = test_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "repeated_test(data, true_label,train_data, test_data, train_label, test_label, \"different_file_test\") # repeat cross test 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: COLOCATED_OPENSTACK.csv\n",
      "Initial data shape:  (2764, 16)\n",
      "Test Data: COLOCATED_WIKIMEDIA.csv\n",
      "Initial data shape:  (2845, 16)\n",
      "-------DT-------\n",
      "Recall: 0.4353815513486182\n",
      "Precision: 0.4244358697272398\n",
      "f1 score: 0.4272874700151605\n",
      "-------KNN-------\n",
      "Recall: 0.44440890391720417\n",
      "Precision: 0.44331254776734125\n",
      "f1 score: 0.43564127463258845\n",
      "-------SVM-------\n",
      "Recall: 0.44942513361626746\n",
      "Precision: 0.4011966262538711\n",
      "f1 score: 0.40302669065682445\n",
      "-------NB-------\n",
      "Recall: 0.428254555814337\n",
      "Precision: 0.47438793638476734\n",
      "f1 score: 0.42999323600733186\n",
      "-------RF-------\n",
      "Recall: 0.4343844504558582\n",
      "Precision: 0.43450025302996265\n",
      "f1 score: 0.42443321363636466\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_OPENSTACK.csv') \n",
    "print(\"Train Data: COLOCATED_OPENSTACK.csv\")\n",
    "print(\"Initial data shape: \", train_data.shape)\n",
    "train_label = train_data['COLOCATED_STATUS']\n",
    "train_label = convert_label_to_numeric(train_label)\n",
    "train_data = train_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "test_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_WIKIMEDIA.csv') \n",
    "print(\"Test Data: COLOCATED_WIKIMEDIA.csv\")\n",
    "print(\"Initial data shape: \", test_data.shape)\n",
    "test_label = test_data['COLOCATED_STATUS']\n",
    "test_label = convert_label_to_numeric(test_label)\n",
    "test_data = test_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "repeated_test(data, true_label,train_data, test_data, train_label, test_label, \"different_file_test\") # repeat cross test 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: COLOCATED_WIKIMEDIA.csv\n",
      "Initial data shape:  (2845, 16)\n",
      "Test Data: COLOCATED_MOZILLA.csv\n",
      "Initial data shape:  (1613, 16)\n",
      "-------DT-------\n",
      "Recall: 0.4312992785620672\n",
      "Precision: 0.397389023107463\n",
      "f1 score: 0.3881521024609301\n",
      "-------KNN-------\n",
      "Recall: 0.42347884856927304\n",
      "Precision: 0.4426324317292113\n",
      "f1 score: 0.4274252106189893\n",
      "-------SVM-------\n",
      "Recall: 0.5204095302270495\n",
      "Precision: 0.49739887422507073\n",
      "f1 score: 0.4753060516783668\n",
      "-------NB-------\n",
      "Recall: 0.39308248551946035\n",
      "Precision: 0.4019187800889135\n",
      "f1 score: 0.3909908012077804\n",
      "-------RF-------\n",
      "Recall: 0.42898775671884914\n",
      "Precision: 0.45568073681438204\n",
      "f1 score: 0.43851601413582275\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_WIKIMEDIA.csv') \n",
    "print(\"Train Data: COLOCATED_WIKIMEDIA.csv\")\n",
    "print(\"Initial data shape: \", train_data.shape)\n",
    "train_label = train_data['COLOCATED_STATUS']\n",
    "train_label = convert_label_to_numeric(train_label)\n",
    "train_data = train_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "test_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_MOZILLA.csv') \n",
    "print(\"Test Data: COLOCATED_MOZILLA.csv\")\n",
    "print(\"Initial data shape: \", test_data.shape)\n",
    "test_label = test_data['COLOCATED_STATUS']\n",
    "test_label = convert_label_to_numeric(test_label)\n",
    "test_data = test_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "repeated_test(data, true_label,train_data, test_data, train_label, test_label, \"different_file_test\") # repeat cross test 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: COLOCATED_WIKIMEDIA.csv\n",
      "Initial data shape:  (2845, 16)\n",
      "Test Data: COLOCATED_OPENSTACK.csv\n",
      "Initial data shape:  (2764, 16)\n",
      "-------DT-------\n",
      "Recall: 0.42635198554841497\n",
      "Precision: 0.43385713698572725\n",
      "f1 score: 0.4176285612148337\n",
      "-------KNN-------\n",
      "Recall: 0.4098970555201733\n",
      "Precision: 0.4495371833928144\n",
      "f1 score: 0.4139116370520181\n",
      "-------SVM-------\n",
      "Recall: 0.4194227255119136\n",
      "Precision: 0.41393147255455665\n",
      "f1 score: 0.4119307714304363\n",
      "-------NB-------\n",
      "Recall: 0.4143625517795123\n",
      "Precision: 0.5002094612147998\n",
      "f1 score: 0.41226109054007026\n",
      "-------RF-------\n",
      "Recall: 0.40134375726456095\n",
      "Precision: 0.4517322547854231\n",
      "f1 score: 0.4026094783094143\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_WIKIMEDIA.csv') \n",
    "print(\"Train Data: COLOCATED_WIKIMEDIA.csv\")\n",
    "print(\"Initial data shape: \", train_data.shape)\n",
    "train_label = train_data['COLOCATED_STATUS']\n",
    "train_label = convert_label_to_numeric(train_label)\n",
    "train_data = train_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "test_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_OPENSTACK.csv') \n",
    "print(\"Test Data: COLOCATED_OPENSTACK.csv\")\n",
    "print(\"Initial data shape: \", test_data.shape)\n",
    "test_label = test_data['COLOCATED_STATUS']\n",
    "test_label = convert_label_to_numeric(test_label)\n",
    "test_data = test_data.drop(columns=['FILE_PATH', 'ICP_STATUS', 'COLOCATED_STATUS', 'SAME_DIFF_STATUS'])\n",
    "\n",
    "repeated_test(data, true_label,train_data, test_data, train_label, test_label, \"different_file_test\") # repeat cross test 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
