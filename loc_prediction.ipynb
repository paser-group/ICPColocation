{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm, tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_file (filename):\n",
    "    df = pd.read_csv(filename)  # read the csv file\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_to_numeric(label):\n",
    "    converted_label = np.empty(len(label), dtype=object) \n",
    "    for i in range(len(label)):\n",
    "        if label[i] == \"ONLY_ONE\":\n",
    "            converted_label[i] = 1\n",
    "        elif label[i] == \"NEUTRAL\":\n",
    "            converted_label[i] = 0\n",
    "        else: \n",
    "            converted_label[i] = 2\n",
    "    converted_label = converted_label.astype('int')\n",
    "    return converted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_CART(train, test, train_label, test_label):\n",
    "    clf = tree.DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                                      min_samples_split = 2, min_weight_fraction_leaf=0.0)\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_KNN(train, test, train_label, test_label):\n",
    "    clf = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_SVM(train, test, train_label, test_label):\n",
    "    clf = svm.SVC(gamma='auto', C = 20.0, kernel='rbf', class_weight = {0:1, 1:1, 2:5})\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_NB(train, test, train_label, test_label):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_RF(train, test, train_label, test_label):\n",
    "    clf = RandomForestClassifier(n_estimators=10, criterion='gini')\n",
    "    clf.fit(train, train_label)\n",
    "    predicted_label = clf.predict(test)\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance(true_label, predicted_label):   \n",
    "    report = classification_report(true_label, predicted_label, digits=3)\n",
    "    recall = recall_score(true_label, predicted_label, average=\"macro\")\n",
    "    precision = precision_score(true_label, predicted_label, average=\"macro\")\n",
    "    f1 = f1_score(true_label, predicted_label, average=\"macro\")\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cv(data, true_label):\n",
    "    # 10 fold cv\n",
    "    kf = KFold(n_splits=10, shuffle = True, random_state = 7)\n",
    "\n",
    "    cv_recall_DT = []\n",
    "    cv_precision_DT = []\n",
    "    cv_f1_DT = []\n",
    "\n",
    "    cv_recall_KNN = []\n",
    "    cv_precision_KNN = []\n",
    "    cv_f1_KNN = []\n",
    "\n",
    "    cv_recall_SVM = []\n",
    "    cv_precision_SVM = []\n",
    "    cv_f1_SVM = []\n",
    "\n",
    "    cv_recall_NB = []\n",
    "    cv_precision_NB = []\n",
    "    cv_f1_NB = []\n",
    "\n",
    "    cv_recall_RF = []\n",
    "    cv_precision_RF = []\n",
    "    cv_f1_RF = []\n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train, test = data.loc[train_index], data.loc[test_index]\n",
    "        train_label, test_label = true_label[train_index], true_label[test_index]\n",
    "    \n",
    "        train = train.values.reshape(-1, 1)\n",
    "        test = test.values.reshape(-1, 1)\n",
    "\n",
    "        recall, precision, f1 = perfrom_CART(train, test, train_label, test_label)\n",
    "        cv_recall_DT.append(recall)\n",
    "        cv_precision_DT.append(precision)\n",
    "        cv_f1_DT.append(f1)\n",
    "\n",
    "        recall, precision, f1 = perfrom_KNN(train, test, train_label, test_label)\n",
    "        cv_recall_KNN.append(recall)\n",
    "        cv_precision_KNN.append(precision)\n",
    "        cv_f1_KNN.append(f1)\n",
    "\n",
    "        recall, precision, f1 = perfrom_SVM(train, test, train_label, test_label)\n",
    "        cv_recall_SVM.append(recall)\n",
    "        cv_precision_SVM.append(precision)\n",
    "        cv_f1_SVM.append(f1)\n",
    "\n",
    "        recall, precision, f1 = perfrom_NB(train, test, train_label, test_label)\n",
    "        cv_recall_NB.append(recall)\n",
    "        cv_precision_NB.append(precision)\n",
    "        cv_f1_NB.append(f1)\n",
    "\n",
    "        recall, precision, f1 = perfrom_RF(train, test, train_label, test_label)\n",
    "        cv_recall_RF.append(recall)\n",
    "        cv_precision_RF.append(precision)\n",
    "        cv_f1_RF.append(f1)\n",
    "\n",
    "    recall_DT = np.mean(cv_recall_DT)\n",
    "    precision_DT = np.mean(cv_precision_DT)\n",
    "    f1_DT = np.mean(cv_f1_DT)\n",
    "\n",
    "    recall_KNN = np.mean(cv_recall_KNN)\n",
    "    precision_KNN = np.mean(cv_precision_KNN)\n",
    "    f1_KNN = np.mean(cv_f1_KNN)\n",
    "\n",
    "    recall_SVM = np.mean(cv_recall_SVM)\n",
    "    precision_SVM = np.mean(cv_precision_SVM)\n",
    "    f1_SVM =  np.mean(cv_f1_SVM)\n",
    "\n",
    "    recall_NB = np.mean(cv_recall_NB)\n",
    "    precision_NB = np.mean(cv_precision_NB)\n",
    "    f1_NB = np.mean(cv_f1_NB)\n",
    "\n",
    "    recall_RF = np.mean(cv_recall_RF)\n",
    "    precision_RF = np.mean(cv_precision_RF)\n",
    "    f1_RF = np.mean(cv_f1_RF)\n",
    "    \n",
    "    return recall_DT, precision_DT, f1_DT, recall_KNN, precision_KNN, f1_KNN, recall_SVM, precision_SVM,\\\n",
    "    f1_SVM, recall_NB, precision_NB, f1_NB, recall_RF, precision_RF, f1_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def different_file_test(train, test, train_label, test_label):\n",
    "    \n",
    "    train = train.values.reshape(-1, 1)\n",
    "    test = test.values.reshape(-1, 1)\n",
    "\n",
    "    recall_DT, precision_DT, f1_DT = perfrom_CART(train, test, train_label, test_label)\n",
    "    recall_KNN, precision_KNN, f1_KNN = perfrom_KNN(train, test, train_label, test_label)\n",
    "    recall_SVM, precision_SVM, f1_SVM = perfrom_SVM(train, test, train_label, test_label)\n",
    "    recall_NB, precision_NB, f1_NB = perfrom_NB(train, test, train_label, test_label)\n",
    "    recall_RF, precision_RF, f1_RF = perfrom_RF(train, test, train_label, test_label)\n",
    "\n",
    "    return recall_DT, precision_DT, f1_DT, recall_KNN, precision_KNN, f1_KNN, recall_SVM, precision_SVM,\\\n",
    "    f1_SVM, recall_NB, precision_NB, f1_NB, recall_RF, precision_RF, f1_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_test(data, true_label, train_data, test_data, train_label, test_label, test_name):\n",
    "    repeated_recall_DT = []\n",
    "    repeated_precision_DT = []\n",
    "    repeated_f1_DT = []\n",
    "\n",
    "    repeated_recall_KNN = []\n",
    "    repeated_precision_KNN = []\n",
    "    repeated_f1_KNN = []\n",
    "\n",
    "    repeated_recall_SVM = []\n",
    "    repeated_precision_SVM = []\n",
    "    repeated_f1_SVM = []\n",
    "\n",
    "    repeated_recall_NB = []\n",
    "    repeated_precision_NB = []\n",
    "    repeated_f1_NB = []\n",
    "\n",
    "    repeated_recall_RF = []\n",
    "    repeated_precision_RF = []\n",
    "    repeated_f1_RF = []\n",
    "    \n",
    "    recall_DT= precision_DT= f1_DT= recall_KNN= precision_KNN= f1_KNN= recall_SVM= precision_SVM= f1_SVM\\\n",
    "    = recall_NB= precision_NB= f1_NB= recall_RF= precision_RF= f1_RF = 0\n",
    "    \n",
    "    for i in range(10):\n",
    "        if test_name == \"k_fold\":\n",
    "            recall_DT, precision_DT, f1_DT, recall_KNN, precision_KNN, f1_KNN, recall_SVM, precision_SVM, f1_SVM,\\\n",
    "            recall_NB, precision_NB, f1_NB, recall_RF, precision_RF, f1_RF = kfold_cv(data, true_label)\n",
    "        else: \n",
    "            recall_DT, precision_DT, f1_DT, recall_KNN, precision_KNN, f1_KNN, recall_SVM, precision_SVM, f1_SVM,\\\n",
    "            recall_NB, precision_NB, f1_NB, recall_RF, precision_RF, f1_RF = different_file_test(train_data, test_data, train_label, test_label)\n",
    "        \n",
    "        repeated_recall_DT.append(recall_DT)\n",
    "        repeated_precision_DT.append(precision_DT)\n",
    "        repeated_f1_DT.append(f1_DT)\n",
    "\n",
    "        repeated_recall_KNN.append(recall_KNN)\n",
    "        repeated_precision_KNN.append(precision_KNN)\n",
    "        repeated_f1_KNN.append(f1_KNN)\n",
    "\n",
    "        repeated_recall_SVM.append(recall_SVM)\n",
    "        repeated_precision_SVM.append(precision_SVM)\n",
    "        repeated_f1_SVM.append(f1_SVM)\n",
    "\n",
    "        repeated_recall_NB.append(recall_NB)\n",
    "        repeated_precision_NB.append(precision_NB)\n",
    "        repeated_f1_NB.append(f1_NB)\n",
    "\n",
    "        repeated_recall_RF.append(recall_RF)\n",
    "        repeated_precision_RF.append(precision_RF)\n",
    "        repeated_f1_RF.append(f1_RF)\n",
    "        \n",
    "    print(\"-------DT-------\")\n",
    "    print(\"Recall:\", np.mean(repeated_recall_DT))\n",
    "    print(\"Precision:\", np.mean(repeated_precision_DT))\n",
    "    print(\"f1 score:\", np.mean(repeated_f1_DT))\n",
    "\n",
    "    print(\"-------KNN-------\")\n",
    "    print(\"Recall:\", np.mean(repeated_recall_KNN))\n",
    "    print(\"Precision:\", np.mean(repeated_precision_KNN))\n",
    "    print(\"f1 score:\", np.mean(repeated_f1_KNN))\n",
    "\n",
    "    print(\"-------SVM-------\")\n",
    "    print(\"Recall:\", np.mean(repeated_recall_SVM))\n",
    "    print(\"Precision:\", np.mean(repeated_precision_SVM))\n",
    "    print(\"f1 score:\", np.mean(repeated_f1_SVM))\n",
    "\n",
    "    print(\"-------NB-------\")\n",
    "    print(\"Recall:\", np.mean(repeated_recall_NB))\n",
    "    print(\"Precision:\", np.mean(repeated_precision_NB))\n",
    "    print(\"f1 score:\", np.mean(repeated_f1_NB))\n",
    "\n",
    "    print(\"-------RF-------\")\n",
    "    print(\"Recall:\", np.mean(repeated_recall_RF))\n",
    "    print(\"Precision:\", np.mean(repeated_precision_RF))\n",
    "    print(\"f1 score:\", np.mean(repeated_f1_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, true_label, train_data, test_data, train_label, test_label = [], [], [], [], [], [] # necessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set: COLOCATED_MOZILLA.csv\n",
      "Initial data shape:  (1613, 16)\n",
      "-------DT-------\n",
      "Recall: 0.41572713442997034\n",
      "Precision: 0.5110221674627831\n",
      "f1 score: 0.43338684199058025\n",
      "-------KNN-------\n",
      "Recall: 0.42965053873235864\n",
      "Precision: 0.539489015177805\n",
      "f1 score: 0.44910230032026843\n",
      "-------SVM-------\n",
      "Recall: 0.45550077382879567\n",
      "Precision: 0.424911509349737\n",
      "f1 score: 0.4030116073734521\n",
      "-------NB-------\n",
      "Recall: 0.4037389152735341\n",
      "Precision: 0.4642102141034051\n",
      "f1 score: 0.40853637290801226\n",
      "-------RF-------\n",
      "Recall: 0.44013527353876103\n",
      "Precision: 0.52916788496674\n",
      "f1 score: 0.4581714113308257\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_MOZILLA.csv') \n",
    "print(\"Data set: COLOCATED_MOZILLA.csv\")\n",
    "print(\"Initial data shape: \", data.shape)\n",
    "true_label = data['COLOCATED_STATUS']\n",
    "true_label = convert_label_to_numeric(true_label)\n",
    "data = data['SLOC']\n",
    "\n",
    "repeated_test(data, true_label, train_data, test_data, train_label, test_label, \"k_fold\") #repeat kfold 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set: COLOCATED_OPENSTACK.csv\n",
      "Initial data shape:  (2764, 16)\n",
      "-------DT-------\n",
      "Recall: 0.39760620796636553\n",
      "Precision: 0.41770791145529496\n",
      "f1 score: 0.3922563068381565\n",
      "-------KNN-------\n",
      "Recall: 0.39840034915619343\n",
      "Precision: 0.40484213251059975\n",
      "f1 score: 0.3930734967931312\n",
      "-------SVM-------\n",
      "Recall: 0.4207782793525867\n",
      "Precision: 0.3952626733087973\n",
      "f1 score: 0.3618425087115513\n",
      "-------NB-------\n",
      "Recall: 0.38645646155537217\n",
      "Precision: 0.4375992558755752\n",
      "f1 score: 0.37254313240702286\n",
      "-------RF-------\n",
      "Recall: 0.40348283596968393\n",
      "Precision: 0.41466271225846346\n",
      "f1 score: 0.39911595352601575\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_OPENSTACK.csv') \n",
    "print(\"Data set: COLOCATED_OPENSTACK.csv\")\n",
    "print(\"Initial data shape: \", data.shape)\n",
    "true_label = data['COLOCATED_STATUS']\n",
    "true_label = convert_label_to_numeric(true_label)\n",
    "data = data['SLOC']\n",
    "\n",
    "repeated_test(data, true_label, train_data, test_data, train_label, test_label, \"k_fold\") #repeat kfold 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set: COLOCATED_WIKIMEDIA.csv\n",
      "Initial data shape:  (2845, 16)\n",
      "-------DT-------\n",
      "Recall: 0.37525074793207136\n",
      "Precision: 0.3984131804524734\n",
      "f1 score: 0.3646253518663737\n",
      "-------KNN-------\n",
      "Recall: 0.3749551100623027\n",
      "Precision: 0.3815726794762887\n",
      "f1 score: 0.36665003332844576\n",
      "-------SVM-------\n",
      "Recall: 0.4450331346356779\n",
      "Precision: 0.3830282001503932\n",
      "f1 score: 0.3863148917761151\n",
      "-------NB-------\n",
      "Recall: 0.3939063966980324\n",
      "Precision: 0.44359319063661956\n",
      "f1 score: 0.38823007836213674\n",
      "-------RF-------\n",
      "Recall: 0.3859995758341783\n",
      "Precision: 0.4040791116654341\n",
      "f1 score: 0.3789451274050627\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_WIKIMEDIA.csv') \n",
    "print(\"Data set: COLOCATED_WIKIMEDIA.csv\")\n",
    "print(\"Initial data shape: \", data.shape)\n",
    "true_label = data['COLOCATED_STATUS']\n",
    "true_label = convert_label_to_numeric(true_label)\n",
    "data = data['SLOC']\n",
    "\n",
    "repeated_test(data, true_label, train_data, test_data, train_label, test_label, \"k_fold\") #repeat kfold 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: COLOCATED_MOZILLA.csv\n",
      "Initial data shape:  (1613, 16)\n",
      "Test Data: COLOCATED_OPENSTACK.csv\n",
      "Initial data shape:  (2764, 16)\n",
      "-------DT-------\n",
      "Recall: 0.4094712212861161\n",
      "Precision: 0.4474110173327663\n",
      "f1 score: 0.41239764887783215\n",
      "-------KNN-------\n",
      "Recall: 0.40899423297923576\n",
      "Precision: 0.4329799329202433\n",
      "f1 score: 0.41249811683228926\n",
      "-------SVM-------\n",
      "Recall: 0.37149949146266625\n",
      "Precision: 0.37515068958833764\n",
      "f1 score: 0.3686354720530009\n",
      "-------NB-------\n",
      "Recall: 0.40272500288909424\n",
      "Precision: 0.4046177260738529\n",
      "f1 score: 0.39680263816418654\n",
      "-------RF-------\n",
      "Recall: 0.4066282299621145\n",
      "Precision: 0.4300793422021827\n",
      "f1 score: 0.4081915006682495\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_MOZILLA.csv') \n",
    "print(\"Train Data: COLOCATED_MOZILLA.csv\")\n",
    "print(\"Initial data shape: \", train_data.shape)\n",
    "train_label = train_data['COLOCATED_STATUS']\n",
    "train_label = convert_label_to_numeric(train_label)\n",
    "train_data = train_data['SLOC']\n",
    "\n",
    "test_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_OPENSTACK.csv') \n",
    "print(\"Test Data: COLOCATED_OPENSTACK.csv\")\n",
    "print(\"Initial data shape: \", test_data.shape)\n",
    "test_label = test_data['COLOCATED_STATUS']\n",
    "test_label = convert_label_to_numeric(test_label)\n",
    "test_data = test_data['SLOC']\n",
    "\n",
    "repeated_test(data, true_label,train_data, test_data, train_label, test_label, \"different_file_test\") # repeat cross test 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data shape:  (1613, 16)\n",
      "Train Data: COLOCATED_MOZILLA.csv\n",
      "Test Data: COLOCATED_WIKIMEDIA.csv\n",
      "Initial data shape:  (2845, 16)\n",
      "-------DT-------\n",
      "Recall: 0.39789636255091354\n",
      "Precision: 0.5111980322951875\n",
      "f1 score: 0.40366944389541015\n",
      "-------KNN-------\n",
      "Recall: 0.4068537758126782\n",
      "Precision: 0.4929807042811197\n",
      "f1 score: 0.41616061387550857\n",
      "-------SVM-------\n",
      "Recall: 0.4050921298824073\n",
      "Precision: 0.45228993454572414\n",
      "f1 score: 0.39998831979118415\n",
      "-------NB-------\n",
      "Recall: 0.4036792897805549\n",
      "Precision: 0.44141589470362186\n",
      "f1 score: 0.4001907080326152\n",
      "-------RF-------\n",
      "Recall: 0.4054762997413084\n",
      "Precision: 0.47560688011473407\n",
      "f1 score: 0.41319036622495\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_MOZILLA.csv') \n",
    "print(\"Initial data shape: \", train_data.shape)\n",
    "print(\"Train Data: COLOCATED_MOZILLA.csv\")\n",
    "train_label = train_data['COLOCATED_STATUS']\n",
    "train_label = convert_label_to_numeric(train_label)\n",
    "train_data = train_data['SLOC']\n",
    "\n",
    "test_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_WIKIMEDIA.csv') \n",
    "print(\"Test Data: COLOCATED_WIKIMEDIA.csv\")\n",
    "print(\"Initial data shape: \", test_data.shape)\n",
    "test_label = test_data['COLOCATED_STATUS']\n",
    "test_label = convert_label_to_numeric(test_label)\n",
    "test_data = test_data['SLOC']\n",
    "\n",
    "repeated_test(data, true_label,train_data, test_data, train_label, test_label, \"different_file_test\") # repeat cross test 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: COLOCATED_OPENSTACK.csv\n",
      "Initial data shape:  (2764, 16)\n",
      "Test Data: COLOCATED_MOZILLA.csv\n",
      "Initial data shape:  (1613, 16)\n",
      "-------DT-------\n",
      "Recall: 0.387193261142841\n",
      "Precision: 0.40881523013778953\n",
      "f1 score: 0.38656256391810023\n",
      "-------KNN-------\n",
      "Recall: 0.4043758917708498\n",
      "Precision: 0.3922945979998088\n",
      "f1 score: 0.3971345857953023\n",
      "-------SVM-------\n",
      "Recall: 0.4879702722839978\n",
      "Precision: 0.38479330988279903\n",
      "f1 score: 0.36371063833142303\n",
      "-------NB-------\n",
      "Recall: 0.36289936850160937\n",
      "Precision: 0.4702024115384093\n",
      "f1 score: 0.3563654355297993\n",
      "-------RF-------\n",
      "Recall: 0.40388638996509335\n",
      "Precision: 0.4263576329978732\n",
      "f1 score: 0.40443123736484987\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_OPENSTACK.csv') \n",
    "print(\"Train Data: COLOCATED_OPENSTACK.csv\")\n",
    "print(\"Initial data shape: \", train_data.shape)\n",
    "train_label = train_data['COLOCATED_STATUS']\n",
    "train_label = convert_label_to_numeric(train_label)\n",
    "train_data = train_data['SLOC']\n",
    "\n",
    "test_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_MOZILLA.csv') \n",
    "print(\"Test Data: COLOCATED_MOZILLA.csv\")\n",
    "print(\"Initial data shape: \", test_data.shape)\n",
    "test_label = test_data['COLOCATED_STATUS']\n",
    "test_label = convert_label_to_numeric(test_label)\n",
    "test_data = test_data['SLOC']\n",
    "\n",
    "repeated_test(data, true_label,train_data, test_data, train_label, test_label, \"different_file_test\") # repeat cross test 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: COLOCATED_OPENSTACK.csv\n",
      "Initial data shape:  (2764, 16)\n",
      "Test Data: COLOCATED_WIKIMEDIA.csv\n",
      "Initial data shape:  (2845, 16)\n",
      "-------DT-------\n",
      "Recall: 0.36683151902340155\n",
      "Precision: 0.39047926474244327\n",
      "f1 score: 0.352044917745898\n",
      "-------KNN-------\n",
      "Recall: 0.37449388458467014\n",
      "Precision: 0.3691686187959396\n",
      "f1 score: 0.3636014196404323\n",
      "-------SVM-------\n",
      "Recall: 0.44081193288220766\n",
      "Precision: 0.3784251808592579\n",
      "f1 score: 0.3718884390825007\n",
      "-------NB-------\n",
      "Recall: 0.3662792869785319\n",
      "Precision: 0.45925809210822494\n",
      "f1 score: 0.34698949295822856\n",
      "-------RF-------\n",
      "Recall: 0.37890148220661646\n",
      "Precision: 0.46104134385769957\n",
      "f1 score: 0.3700565128873339\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_OPENSTACK.csv') \n",
    "print(\"Train Data: COLOCATED_OPENSTACK.csv\")\n",
    "print(\"Initial data shape: \", train_data.shape)\n",
    "train_label = train_data['COLOCATED_STATUS']\n",
    "train_label = convert_label_to_numeric(train_label)\n",
    "train_data = train_data['SLOC']\n",
    "\n",
    "test_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_WIKIMEDIA.csv') \n",
    "print(\"Test Data: COLOCATED_WIKIMEDIA.csv\")\n",
    "print(\"Initial data shape: \", test_data.shape)\n",
    "test_label = test_data['COLOCATED_STATUS']\n",
    "test_label = convert_label_to_numeric(test_label)\n",
    "test_data = test_data['SLOC']\n",
    "\n",
    "repeated_test(data, true_label,train_data, test_data, train_label, test_label, \"different_file_test\") # repeat cross test 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: COLOCATED_WIKIMEDIA.csv\n",
      "Initial data shape:  (2845, 16)\n",
      "Test Data: COLOCATED_MOZILLA.csv\n",
      "Initial data shape:  (1613, 16)\n",
      "-------DT-------\n",
      "Recall: 0.40451716628595147\n",
      "Precision: 0.5542149946046908\n",
      "f1 score: 0.4156684560039\n",
      "-------KNN-------\n",
      "Recall: 0.4192987711249385\n",
      "Precision: 0.5795674645509441\n",
      "f1 score: 0.4293572314362784\n",
      "-------SVM-------\n",
      "Recall: 0.4605963597560236\n",
      "Precision: 0.3723537950295979\n",
      "f1 score: 0.362182296231376\n",
      "-------NB-------\n",
      "Recall: 0.38686585745409274\n",
      "Precision: 0.4657199572453809\n",
      "f1 score: 0.39113405732597467\n",
      "-------RF-------\n",
      "Recall: 0.4087451724176317\n",
      "Precision: 0.4893996513203204\n",
      "f1 score: 0.41588467378162697\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_WIKIMEDIA.csv') \n",
    "print(\"Train Data: COLOCATED_WIKIMEDIA.csv\")\n",
    "print(\"Initial data shape: \", train_data.shape)\n",
    "train_label = train_data['COLOCATED_STATUS']\n",
    "train_label = convert_label_to_numeric(train_label)\n",
    "train_data = train_data['SLOC']\n",
    "\n",
    "test_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_MOZILLA.csv') \n",
    "print(\"Test Data: COLOCATED_MOZILLA.csv\")\n",
    "print(\"Initial data shape: \", test_data.shape)\n",
    "test_label = test_data['COLOCATED_STATUS']\n",
    "test_label = convert_label_to_numeric(test_label)\n",
    "test_data = test_data['SLOC']\n",
    "\n",
    "repeated_test(data, true_label,train_data, test_data, train_label, test_label, \"different_file_test\") # repeat cross test 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: COLOCATED_WIKIMEDIA.csv\n",
      "Initial data shape:  (2845, 16)\n",
      "Test Data: COLOCATED_OPENSTACK.csv\n",
      "Initial data shape:  (2764, 16)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_WIKIMEDIA.csv') \n",
    "print(\"Train Data: COLOCATED_WIKIMEDIA.csv\")\n",
    "print(\"Initial data shape: \", train_data.shape)\n",
    "train_label = train_data['COLOCATED_STATUS']\n",
    "train_label = convert_label_to_numeric(train_label)\n",
    "train_data = train_data['SLOC']\n",
    "\n",
    "test_data = pd.read_csv('..//updated_data//RAW_DATASETS//COLOCATED_OPENSTACK.csv') \n",
    "print(\"Test Data: COLOCATED_OPENSTACK.csv\")\n",
    "print(\"Initial data shape: \", test_data.shape)\n",
    "test_label = test_data['COLOCATED_STATUS']\n",
    "test_label = convert_label_to_numeric(test_label)\n",
    "test_data = test_data['SLOC']\n",
    "\n",
    "repeated_test(data, true_label,train_data, test_data, train_label, test_label, \"different_file_test\") # repeat cross test 10 times and report avarage performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
